\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage{amsmath,amsthm, amssymb}
\usepackage[margin=3cm]{geometry}
\usepackage{mathtools}
\usepackage{dsfont}
\usepackage{xcolor}
\usepackage{algorithm,algpseudocode}
\usepackage{todonotes}
\usepackage{nicefrac}
\usepackage{mathrsfs}
\usepackage{tikz}
\usepackage{thm-restate}


%%%%%%%%    THEOREM DEFINITIONS AND RESTATABLE
% \newcounter{claim}
% \setcounter{claim}{0}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{claim}[theorem]{Claim}

\usepackage{todonotes}

\newcommand{\matt}[1]{\todo[color=red!50, prepend, caption={Matt}, tickmarkheight=0.25cm]{#1}}
\newcommand{\note}[1]{\emph{Note: #1}}
\newcommand{\conjecture}[1]{ \noindent\emph{\textbf{Conjecture:}} \emph{ #1 }}




%%%%%%%%    NOTATION DEFINITIONS FOR EASIER WRITING
\newcommand{\ket}[1]{|#1\rangle}
\newcommand{\bra}[1]{\langle #1|}
\newcommand{\braket}[2]{\langle #1|#2\rangle}
\newcommand{\ketbra}[2]{| #1\rangle\! \langle #2|}
\newcommand{\parens}[1]{\left( #1 \right)}
\newcommand{\brackets}[1]{\left[ #1 \right]}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\norm}[1]{\left| \left| #1 \right| \right|}
\newcommand{\diamondnorm}[1]{\left| \left| #1 \right| \right|_\diamond}
\newcommand{\anglebrackets}[1]{\left< #1 \right>}
\newcommand{\overlap}[2]{\anglebrackets{#1 , #2 }}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\openone}{\mathds{1}}
\newcommand{\expect}[1]{\mathbb{E}\brackets{#1}}
\newcommand{\variance}[1]{\textit{Var} \brackets{ #1 }}
\newcommand{\prob}[1]{\text{Pr}\left[ #1 \right]}
\newcommand{\bigo}[1]{O\left( #1 \right)}
\newcommand{\bigotilde}[1]{\widetilde{O} \left( #1 \right)}
\newcommand{\ts}{\textsuperscript}

\DeclareMathOperator{\Tr}{Tr}
\newcommand{\trace}[1]{\Tr \brackets{ #1 }}
\newcommand{\partrace}[2]{\Tr_{#1} \brackets{ #2 }}
\newcommand{\complex}{\mathbb{C}}

%%%%% COMMONLY USED OBJECTS
\newcommand{\hilb}{\mathcal{H}}
\newcommand{\partfun}{\mathcal{Z}}
\newcommand{\identity}{\mathds{1}}
\newcommand{\gue}{\rm GUE}
\DeclareMathOperator{\sinc}{sinc}
\DeclareMathOperator{\hermMathOp}{Herm}
\newcommand{\herm}[1]{\hermMathOp\parens{#1}}


\title{Thermal State Prep}
\author{Nathan Wiebe, Matthew Hagan}
\date{May 2022}

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
Going to leave this blank for now. \cite{shiraishi_undecidability_2021}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Preliminaries}
We denote the Hilbert space of the system as $\hilb_{S}$ and the environment as $\hilb_{E}$, with the Hamiltonians governing each as $H_{S}$ and $H_{E}$. We will assume without loss of generality that the system's Hilbert space can be encoded with $n$ qubits, giving $\dim_S = 2^{n}$, and the environment's Hilbert space can be encoded with $m$ qubits giving $\dim_E = 2^{m}$. The Hamiltonian for the joint system on $\hilb_{S} \otimes \hilb_{E}$ is then $H = H_{S} \otimes \identity + \identity \otimes H_{E}$. The Hilbert space of the combined system and environment is of dimension $\dim = \dim_E \cdot \dim_S = 2^{n + m}$. 

We will primarily work in the eigenbasis for each Hamiltonian:
\begin{equation}
    H_{S} = \sum_{i = 0}^{2^n - 1} \lambda_S(i) \ketbra{s_i}{s_i} ~,~ H_{E} = \sum_{j=0}^{2^m - 1} \lambda_E(j) \ketbra{e_j}{e_j} ~,~ H = \sum_{i=0}^{2^n - 1} \sum_{j=0}^{2^m - 1} \lambda(i,j) (\ket{s_i} \otimes \ket{e_j})(\bra{s_i} \otimes \bra{e_j}),
\end{equation}
for convenience we will denote the tensor product of eigenvectors simply by their indices $\ket{i,j} \coloneqq \ket{s_i} \otimes \ket{e_j}$. For convenience we define $\lambda(i,j) \coloneqq \lambda_S(i) + \lambda_E(j)$. We also make use of the following notation for the energy differences of the system-environment Hamiltonian
$$\Delta(i,j|k,l) \coloneqq \lambda(i,j) - \lambda(k,l),$$
and will use $\Delta_S(i,j) \coloneqq \lambda_S(i) - \lambda_S(j)$ for just the system differences. To define the degeneracy of each eigenvalue we use the symbol
$$\eta(i,j) \coloneqq \sum_{(k,l) : \Delta(i,j|k,l) = 0} 1.$$ We use the notation $\delta(i,j|k,l)$ to denote the product of Kronecker delta functions $\delta(i,j|k,l) = \delta_{i,k} \delta_{j,l}$.

For input states we will typically assume thermal states of the form $\rho_S(\beta) = \frac{e^{-\beta H_S}}{\partfun_S}$, where $\partfun_S = \trace{e^{-\beta H_S}}$, where the inverse temperature $\beta$ of the partition function will typically be assumed but written explicitly if need be. We will assume environment states of the form $\rho_E(\beta) = \frac{e^{-\beta H_E}}{\partfun_E}$ and we will typically denote the tensor product of the system and environment states as $\rho(\beta_S, \beta_E) = \rho_S(\beta_S) \otimes \rho_E(\beta_E)$. The inputs $\beta_S, \beta_E$ will typically be surpressed in most cases as well.


Overall one application of our channel is represented as
\begin{equation}
    \Phi(\rho) := \int \partrace{\hilb_E}{e^{+i(H + \alpha G)t} \rho e^{-i(H + \alpha G) t}} dG.
\end{equation}
It will prove convenient to study the time evolution of a fixed interaction as a map from the total system-environment space to itself. We denote this channel for a specific random interaction $G$ as
\begin{equation}
    \Phi_G(\rho_S \otimes \rho_E) := e^{+i (H+ \alpha G) t} \rho_S \otimes \rho_E e^{-i (H + \alpha G) t}. \label{eq:phi_g_definition}
\end{equation}
Clearly then $\Phi(\rho_S) = \partrace{env}{\int \Phi_G (\rho_S \otimes \rho_E) dG}$. We use $G$ to denote the randomized interaction term, where $G = U_G D U_G^\dagger$. The measure we choose for the eigenbasis of $G$ is $U_G \sim Haar$ and the eigenvalues are i.i.d with mean 0 and variance $1$.  This gives the overall interaction measure as the decomposition $\int dG = \int \int dD ~ dU_G$. The interaction strength of $G$ will be controlled through the coupling coefficient $\alpha$.

\begin{restatable}{lemma}{haar_two_moment} \label{lem:haar_two_moment}
    Let $U$ be a unitary matrix over $\dim$ dimensions that is distributed according to the Haar measure. Then the following average is
    \begin{align}
        \int \bra{i_1} U \ket{j_1} \bra{i_2} U \ket{j_2} \bra{k_1} U^\dagger \ket{l_1} ~ \bra{k_2} U^\dagger \ket{l_2} dU =& ~\frac{1}{\dim^2 - 1} \parens{\delta_{i_1, l_1} \delta_{j_1, k_1} \delta_{i_2, l_2} \delta_{j_2, k_2} + \delta_{i_1, l_2} \delta_{j_1, k_2} \delta_{i_2, l_1} \delta_{j_2, k_1}} \nonumber \\
        &- \frac{1}{\dim(\dim^2 - 1)} \parens{\delta_{i_1, l_2} \delta_{j_1, k_1} \delta_{i_2, l_1} \delta_{j_2, k_2} + \delta_{i_1, l_1} \delta_{j_1, k_2} \delta_{i_2, l_2} \delta_{j_2, k_1}}. \label{eq:haar_two_moment_integral}
    \end{align}
\end{restatable}

\begin{lemma}{lemma}\label{lem:sinc_poly_approx}
    Let $f(x) = \frac{\sin^2(x)}{x^2}$. The constant approximation $f(x) = 1$ has error $|f(x) - 1| \leq \epsilon_{1}$ if $|x| \leq \sqrt{2 \epsilon_{1}}$. Further, if $x = \Delta t$, with $\Delta \geq \Delta_{\min}$, we note that $t \geq (\Delta_{\min} \sqrt{\epsilon_{\sinc} } )^{-1}$ suffices for $f(\Delta t) \leq \epsilon_{\sinc}$.
\end{lemma}
\begin{proof}
    We use the form of $\sinc$ as $\frac{\sin(x)}{x} = \int_0^1 \cos(sx) ds$. The first 3 derivatives are computed using straightforward calculus
    \begin{align}
        \frac{df}{dx} &= -2 \int_0^1 \sin(sx) s ds \int_0^1 \cos(sx) ds \\
        \frac{d^2f}{dx^2} &= -2 \int_0^1 \cos(sx)s^2 ds \int_0^1 \cos(sx) ds + \int_0^1 \sin(sx) s ~ds \int_0^1 \sin(sx) s ~ds.
        % \frac{d^3 f}{dx^3} &= 2 \int_0^1 \sin(sx)s^3 ds \int_0^1 \cos(sx) ds + 4 \int_0^1 \cos(sx) s^2 ds \int_0^1 \sin(sx) s ds .
    \end{align}
    By using the fact that $\cos(sx) \to 1$ and $\sin(sx) \to 0$ as $x \to 0$ we can evaluate the Taylor's series to $f(x)$ directly. We also make use of the inequality $\abs{\int_a^b f(x) dx} \leq \int_a^b \abs{f(x)} dx$ and that sine and cosine are bounded by 1.
    \begin{align}
        f(x) &= \frac{\sin^2(x)}{x^2} \bigg|_{x = 0} + x \frac{df}{dx}\bigg|_{x = 0} + \frac{x^2}{2!} \frac{d^2f}{dx^2}\bigg|_{x=c} \\
        f(x) &= 1 + \frac{x^2}{2} \frac{d^2f}{dx^2}\bigg|_{x=c}  \\
        \abs{f(x) - 1} &= \frac{\abs{x}^2}{2} \abs{\frac{d^2f}{dx^2}(x=c)} \\
        &\leq \frac{|x|^2}{3}
    \end{align}
    Requiring $|x|^2/3 \leq \epsilon$ yields the statement.
    
    We will also have a need for bounding $f(x)$ when $x$ is of the form $x = \Delta t$. We would like to choose $t$ large enough so that $\Delta \geq \Delta_{\text{min}}$ implies that $f(\Delta t) \leq \epsilon_{\sinc}$. This can be given using the fact that $\sin(x) \leq 1$:
    \begin{align}
        f(\Delta t) &= \frac{\sin^2(\Delta t)}{\Delta^2 t^2} \\
        &\leq \frac{1}{\Delta^2 t^2} \\
        \frac{1}{\Delta_{\text{min}}^2 t^2} &\leq \frac{1}{\Delta^2 t^2} \leq \epsilon_{\sinc} \\
        \frac{1}{\Delta_{\text{min}} \sqrt{\epsilon_{\sinc}}} &\leq t.
    \end{align}
    We now use this bound on $t$ to investigate when the polynomial approximation given above holds for inputs $x = (\Delta - \gamma)t$. We assume $\gamma \geq 0 $.
    \begin{align}
        |(\Delta - \gamma)t| &\leq \sqrt[3]{6\epsilon} \\
        \abs{\Delta - \gamma} &\leq \frac{\sqrt[3]{6 \epsilon}}{t} \\
        &\leq \Delta_{\text{min}} \sqrt{\epsilon_{\sinc}}\sqrt[3]{6 \epsilon}.
    \end{align}
    We also would like to note the differences if one uses the constant term for $f(x)$ as opposed to a quadratic.
    $$f(x) = 1 + x \frac{df}{dx}\bigg|_{x=c}$$
    Using the fact that the first derivative is 0 at $x= 0$ and the second is bounded by $\abs{\frac{d^2f}{dx^2}} \leq 1$, we get
    $$f(x) = 1 + R(x)$$
    and $\abs{R(x)} \leq |x|^2 / 2$ implies that $|x| \leq \sqrt{2\epsilon}$ suffices for $\abs{f(x) - 1} \leq \epsilon$. Using this bound with $f((\Delta - \gamma)t)$, we get $\abs{\Delta - \gamma} \leq \Delta_{\text{min}} \sqrt{2 \epsilon_{\sinc} \epsilon} $.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Taylor's Series for $\Phi$}

\begin{lemma}[First Order $\alpha$ Correction to $\Phi$]
   Given a randomized environment interaction channel $\Phi$ with coupling coefficient $\alpha$, the first order correction is
   \begin{equation}
        \frac{\partial}{\partial \alpha} \Phi(\rho_S) \bigg|_{\alpha = 0} = 0.
   \end{equation}
\end{lemma}
\begin{proof}
    We start by using linearity of derivatives, integration, and partial trace to pull the $\alpha$ derivative to act on $\Phi_G$ as
    \begin{align}
        \frac{\partial}{\partial \alpha} \Phi(\rho_S) \bigg|_{\alpha = 0} &= \frac{\partial}{\partial \alpha} \partrace{\mathcal{H}_E}{\int \Phi_G(\rho_s) dG} \bigg|_{\alpha = 0} \\
         &= \partrace{\mathcal{H}_E}{\int \frac{\partial}{\partial \alpha} \Phi_G(\rho_S) dG \bigg|_{\alpha = 0} } .
    \end{align}
    Now we use Eq. \eqref{eq:phi_g_definition} to compute the derivatives, we remind the reader that $\rho = \rho_S \otimes \rho_E$,
    \begin{align}
        \frac{\partial}{\partial \alpha} \Phi_G (\rho_S) &= \parens{\frac{\partial}{\partial \alpha} e^{+ i (H + \alpha G)t}} \rho e^{-i (H + \alpha G) t} + e^{+i (H + \alpha G)t} \rho \parens{\frac{\partial}{\partial \alpha} e^{- i (H + \alpha G)t}} \\
        &= \parens{\int_{0}^{1} e^{i s (H+\alpha G)t} (i t G) e^{i (1-s) (H+\alpha G)t} ds} \rho e^{-i(H+\alpha G)t} \nonumber \\
    &~ ~+ e^{i(H+\alpha G)t} \rho \parens{\int_{0}^1 e^{-i s (H+\alpha G) t} (- i t G) e^{-i (1-s) (H+\alpha G)t} ds}. \label{eq:first_order_alpha_derivative}
    \end{align}
    We can further simplify this by bringing in the evaluation of $\alpha = 0$ through the partial trace and integration, as they are uniformly convergent over $\alpha$ (is that the correct notion that allows us to switch orders?)
    \begin{align}
        \frac{\partial}{\partial \alpha} \Phi_G(\rho_S) \bigg|_{\alpha = 0} &= i t \int_0^1 e^{i s H t} G e^{-i s H t} ds e^{i H t} \rho e^{-i H t} - i t e^{+i H t} \rho \int_0^1 e^{-is H t} G e^{-i(1-s) Ht} ds \\
        &= i t \parens{\int_0^1 G(s t) ds} \rho(t) - it \rho(t) \parens{\int_0^1 G(s t) ds} \\
        &= i t \int_0^1 [G(s t), \rho(t)] ds,
    \end{align}
    where we have used the Heisenberg picture $\rho(t) = e^{i H t} \rho e^{-i H t}$ to simplify the notation.

    This expression is now amenable to computing the correction to the total channel. We do so by performing the integration over the randomized interactions. We take advantage of the structure of our interaction measure, that is $G = U_G D U_G^\dagger$ and $dG = dU_G dD$, which allows us to write
    \begin{align}
        \int \frac{\partial}{\partial \alpha} \Phi_G(\rho_S) \bigg|_{\alpha = 0} dG &= it \int \int_0^1 \left[ e^{i H s t} G e^{-i H s t}, \rho(t) \right] ds ~dG \\
        &= it \int_0^1 \left[ e^{i H s t} \parens{\int \int U_G D U_G^\dagger ~dU_G ~ dD} e^{-i H s t}, \rho(t)  \right] ds \\
        &= i t \int_0^1 \left[ e^{i H s t} \parens{\int U_G \parens{\int D ~ dD} ~ U_G^\dagger dU_G } e^{-i H s t}, \rho(t) \right] ds \\
        &= 0.
    \end{align}
    This last step relies on the use of random eigenvalues with mean 0, implying $\int D ~dD = 0$ which shows that $\frac{\partial}{\partial \alpha} \Phi(\rho_S) \big|_{\alpha = 0 } = 0$.
\end{proof}

\begin{lemma} \label{lem:two_heisenberg_interactions}
    Let $G(t)$ denote the Heisenberg evolved random interaction $G(t) = e^{iHt} G e^{-iHt}$ for a total Hamiltonian $H$. After averaging over the interaction measure the product $G(x) G(y)$ can be computed as
    \begin{equation}
        \int G(x) G(y) dG = \frac{1}{\dim + 1} \parens{\sum_{(i,j),(k,l)} e^{i \Delta(i,j|k,l) (x-y)} \ketbra{i,j}{i,j} + \identity}.
    \end{equation}
\end{lemma}
\begin{proof}
The overall structure of this proof is to evaluate the product in the Hamiltonian eigenbasis and split the product into three factors: a phase contribution from the time evolution, a Haar integral from the eigenvalues of the random interaction, and the eigenvalue contribution of the random interaction. Since this involves the use of multiple indices, it will greatly simplify the proof to use a single index over the total Hilbert space $\hilb$ as opposed to two indices over $\hilb_S \otimes \hilb_E$. For example, the index $a$ should be thought of as a pair $(a_s, a_e)$, and functions $\lambda(a)$ should be thought of as $\lambda(a_s, a_e)$. Once the final form of the expression is reached we will substitute in pairs of indices for easier use of the lemma in other places.
    \begin{align}
        \int G(x) G(y) dG &= \int e^{+i H x} U_G D U_G^\dagger e^{-i H x} e^{+i H y} U_G D U_G^\dagger e^{-i H y} dU_G ~dD \\
        &= \int \bigg[\sum_a e^{+i \lambda(a)x}\ketbra{a}{a}  U_G \sum_b D(b)\ketbra{b}{b} U_G^\dagger \nonumber \\
        &\quad \sum_c e^{-i \lambda(c) (x - y)} \ketbra{c}{c} U_G \sum_d D(d)\ketbra{d}{d} U_G^\dagger \sum_e e^{-i \lambda(e) y} \ketbra{e}{e} \bigg] dU_G ~dD\\
        &=\sum_{a,b,c,d,e} \ketbra{a}{e} e^{-i (\lambda(c) - \lambda(a))x} e^{-i (\lambda(e) - \lambda(c))y} \nonumber \\
        &\quad \times \int \bra{a} U_G \ket{b} \bra{c} U_G \ket{d} \bra{b} U_G^{\dagger} \ket{c} \bra{d} U_G^\dagger \ket{e} dU_G \int D(b) D(d) dD \\
        &=  \sum_{a, b, c, d, e} \delta_{bd} \ketbra{a}{e} e^{-i (\lambda(c) - \lambda(a))x} e^{-i (\lambda(e) - \lambda(c))y} \nonumber \\
        &\quad \times \int \bra{a} U_G \ket{b} \bra{c} U_G \ket{d} \bra{b} U_G^{\dagger} \ket{c} \bra{d} U_G^\dagger \ket{e} dU_G. \\
    \end{align}
    Now the summation over $d$ fixes $d=b$ and we use Lemma \ref{lem:haar_two_moment} to compute the Haar integral, which simplifies greatly due to the repeated $b$ index. Plugging the result into the above yields the following
    \begin{align}
        &= \frac{1}{\dim^2 - 1} \sum_{a, b, c, e} \ketbra{a}{e} e^{-i (\lambda(c) - \lambda(a))x} e^{-i (\lambda(e) - \lambda(c))y} \parens{\delta_{ac} \delta_{ce} + \delta_{ae} - \frac{1}{\dim} \parens{\delta_{ac} \delta_{ce} + \delta_{ae}}}  \\
        &= \frac{1}{\dim^2 - 1} \parens{1 - \frac{1}{\dim}} \sum_{a, b, c, e} \ketbra{a}{e} e^{-i (\lambda(c) - \lambda(a))x} e^{-i (\lambda(e) - \lambda(c))y} \delta_{ae} (1 + \delta_{ac}) \\
        &= \frac{1}{\dim^2 - 1} \parens{1 - \frac{1}{\dim}} \sum_{a, b, c} \ketbra{a}{a} e^{i (\lambda(a) - \lambda(c))(x-y)} (1 + \delta_{ac}) \\
        &= \frac{1 \parens{\dim - 1}}{\dim^2 - 1} \sum_{a,c} \ketbra{a}{a} e^{i (\lambda(a) - \lambda(c))(x - y)} (1 + \delta_{ac}) \\
        &= \frac{1}{\dim + 1} \parens{\sum_{a,c} e^{i (\lambda(a) - \lambda(c))(x-y)} \ketbra{a}{a} + \identity}.
    \end{align}
    Reindexing by $a \mapsto i,j$, $c \mapsto k,l$, and plugging in the definition of $\Delta$ yields the statement of the lemma.
\end{proof}


\begin{lemma} \label{lem:sandwiched_interaction}
    Given two Heisenberg evolved random interactions, $G(x)$ and $G(y)$, we compute their action on an outer-product $\ketbra{i,j}{k,l}$ as
    \begin{equation}
        \int G(x) \ketbra{i,j}{k,l} G(y) ~dG = \frac{1}{\dim + 1} \parens{\ketbra{i,j}{k,l} + \delta(i,j|k,l) \sum_{m,n} e^{i \Delta(m,n | i,j) (x-y)} \ketbra{m,n}{m,n}}
    \end{equation}
\end{lemma}
\begin{proof}
This proof is structured the same as Lemma \ref{lem:two_heisenberg_interactions} and similarly we will use a single index of the total Hilbert space $\hilb$ and switch to two indices to match the rest of the exposition.
    \begin{align}
        \int G(x) \ketbra{a}{b} G(y) dG &=  \int e^{i H x} U_G D U_G^{\dagger} e^{-i H x} \ketbra{a}{b} e^{i H y} U_G D U_G^\dagger e^{-i H y} ~dG \\
        &= \sum_{c, d, e, f} e^{i (\lambda(c) - \lambda(a))x} e^{i (\lambda(b) - \lambda(f))y} \nonumber \\
        &\quad \times \int \ketbra{c}{c} U_G D(d) \ketbra{d}{d} U_G^\dagger \ketbra{a}{b} U_G D(e) \ketbra{e}{e} U_G^\dagger \ketbra{f}{f} dG \\
        &= \sum_{c, d, e, f}  e^{i (\lambda(c) - \lambda(a))x} e^{i (\lambda(b) - \lambda(f))y} \ketbra{c}{f} \nonumber \\
        &\quad \times \int D(d) D(e) dD \int \bra{c} U_G \ket{d} \bra{b} U_G \ket{e} \bra{d} U_G^\dagger \ket{a} \bra{e} U_G^\dagger \ket{f} dU_G \\
        &=  \sum_{c,d,f} e^{i (\lambda(c) - \lambda(a))x} e^{i (\lambda(b) - \lambda(f))y} \ketbra{c}{f} \nonumber \\ 
        &\quad \times \int \bra{c} U_G \ket{d} \bra{b} U_G \ket{d} \bra{a} \overline{U_G} \ket{d} \bra{f} \overline{U_G} \ket{d} dU_G \\
        &= \frac{1}{\dim^2 - 1} \sum_{c,d,f} e^{i (\lambda(c) - \lambda(a))x} e^{i (\lambda(b) - \lambda(f))y} \ketbra{c}{f} (\delta_{ca} \delta_{bf} + \delta_{cf}\delta_{ab})\parens{1 - \frac{1}{\dim}} \\
        &= \frac{1}{\dim + 1} \sum_{c,f} e^{i (\lambda(c) - \lambda(a))x} e^{i (\lambda(b) - \lambda(f))y} \ketbra{c}{f} (\delta_{ca} \delta_{bf} + \delta_{cf}\delta_{ab}) \\
        &= \frac{1}{\dim + 1} \parens{\ketbra{a}{b} + \delta_{ab} \sum_{c} e^{i(\lambda(c) - \lambda(a))(x-y)} \ketbra{c}{c} }.
    \end{align}
    Now re-indexing by $a \mapsto (i,j)$, $b \mapsto (k,l)$ and $c \mapsto (m,n)$ results in the expression given in the statement of the lemma.
\end{proof}


\begin{lemma}[Second Order Correction] \label{lem:the_double_duhamel}
    Given a system Hamiltonian $H_{S}$, an environment Hamiltonian $H_{E}$, a simulation time $t$, and coupling coefficient $\alpha$, let $\Phi_G : \hilb_S \otimes \hilb_E \to \hilb_S \otimes \hilb_E$ denote the fixed interaction channel 
    \begin{equation}
        \Phi_G(\rho) = e^{+i (H + \alpha G)t} \rho e^{-i (H + \alpha G)t},
    \end{equation}
    where $H = H_S \otimes \identity + \identity \otimes H_E$. We compute the output of the averaged channel at $\alpha = 0$ for the basis $\ketbra{a}{b}$ of linear operators as:
 \begin{align}
     &\int \frac{\partial^2}{\partial \alpha^2} \Phi_G(\ketbra{i,j}{k,l})\bigg|_{\alpha = 0} dG \\
     &= -\frac{2  e^{i \Delta(i,j|k,l) t}}{\dim + 1} \bigg(\sum_{(a,b): \Delta(i,j|a,b) \neq 0} \frac{1 - i \Delta(i,j|a,b)t - e^{-i \Delta(i,j|a,b) t}}{\Delta(i,j|a,b)^2} \nonumber \\
     &~+ \sum_{(a,b): \Delta(k,l|a,b) \neq 0} \frac{1 + i \Delta(k,l|a,b) t - e^{i \Delta(k,l|a,b) t}}{\Delta(k,l|a,b)^2} + \frac{t^2}{2}(\eta(i,j) + \eta(k,l)) \bigg) \ketbra{i,j}{k,l} \nonumber \\
    &~ +\delta_{i,k} \delta_{j,l} \frac{2 e^{i \Delta(i,j|k,l)t}}{\dim+1} \parens{ \sum_{(a,b): \Delta(i,j|a,b) \neq 0 } \frac{2(1- \cos (\Delta(i,j|a,b)t))}{\Delta(i,j|a,b)^2} \ketbra{a,b}{a,b} + t^2 \sum_{(a,b) : \Delta(i,j|a,b) = 0} \ketbra{a,b}{a,b}}
 \end{align}
\end{lemma}
\begin{proof}
To start we would like to note that we will use a single index notation to refer to the joint system-environment eigenbasis during this proof to help shorten the already lengthy expressions. We will convert back to a double index notation to match the statement of the theorem. We start from the expression for the first derivative of the channel $\frac{\partial}{\partial \alpha} \Phi_G(\rho_S)$ given by Eq. \eqref{eq:first_order_alpha_derivative}. To take the second derivative there are six factors involving $\alpha$, so we will end up with six terms. We repeat Eq. \eqref{eq:first_order_alpha_derivative} below, add a derivative, and label each factor containing an $\alpha$ for easier computation
\begin{align}
    \frac{\partial^2}{\partial \alpha^2} \Phi_G(\rho_S) =& \frac{\partial}{\partial \alpha} \parens{\int_{0}^{1} \underset{\substack{\downarrow \\ (A)}}{e^{i s (H+\alpha G)t}} (i t G) \underset{\substack{\downarrow \\ (B)}}{e^{i (1-s) (H+\alpha G)t}} ds ~ \rho \underset{\substack{\downarrow \\ (C)}}{e^{-i(H+\alpha G)t}} } \nonumber \\
    &~ ~+\frac{\partial}{\partial \alpha} \parens{ \underset{\substack{\downarrow \\ (D)} }{e^{i(H+\alpha G)t}} \rho \int_{0}^1 \underset{\substack{\downarrow \\ (E)} }{e^{-i s (H+\alpha G) t} } (- i t G) \underset{\substack{\downarrow \\ (F)}}{e^{-i (1-s) (H+\alpha G)t}} ds }.
\end{align}
Our goal is to get each of these terms in a form in which we can use either Lemma \ref{lem:two_heisenberg_interactions} or \ref{lem:sandwiched_interaction}. 
\begin{align}
    (A) &=i t\int_0^1 \parens{\frac{\partial}{\partial \alpha} e^{i s_1 (H+ \alpha G)t}} G e^{i(1-s_1)(H+\alpha G)t} ds_1 \rho e^{-i (H+\alpha G)t} \bigg|_{\alpha=0} \\
    &= (it)^2 \int_0^1 \parens{\int_0^1 e^{i s_1 s_2 (H+\alpha G)t} s_1 G e^{i s_1 (1-s_2) (H+\alpha G)t} ds_2} G e^{i(1-s_1) (H+\alpha G)t} ds_1 \rho e^{-i(H+\alpha G) t} \bigg|_{\alpha=0} \\
    &= -t^2 \int_0^1 \int_0^1 e^{i s_1 s_2 H t} G e^{-i s_1 s_2 H t} e^{i s_1 H t} G e^{-i s_1 H t} s_1 ds_1 ds_2 e^{i H t} \rho e^{-i H t} \\
    &= -t^2 \int_0^1 \int_0^1 G(s_1 s_2 t) G(s_1 t) s_1 ds_1 ds_2 \rho(t). \label{eq:second_deriv_alpha_first_term}
\end{align}

\begin{align}
    (B) &= it \int_0^1 e^{i s_1 (H + \alpha G)t} G \frac{\partial}{\partial \alpha}\parens{e^{i(1-s_1)(H + \alpha G)t}} ds_1 \rho e^{-i(H + \alpha G) t} \bigg|_{\alpha = 0} \\
    &= (it)^2 \int_0^1 e^{i s_1 (H + \alpha G)t} G \parens{\int_0^1 e^{i(1-s_1)s_2 (H + \alpha G)t} (1-s_1) G e^{i(1 - s_1)(1 - s_2)(H + \alpha G)t} ds_2} ds_1 ~ \rho e^{-i ( H + \alpha G)t} \bigg|_{\alpha = 0} \\
    &= -t^2 \int_0^1 \int_0^1 e^{i s_1 H t} G e^{i(1-s_1)s_2 H t} G e^{i(1-s_1)(1-s_2) H t} (1-s_1) ds_1 ds_2 ~ \rho e^{-i H t}\\ 
    &= -t^2 \int_0^1 \int_0^1 e^{i s_1 H t} G e^{-i s_1 H t} e^{i(s_1 + s_2 - s_1 s_2) H t} G e^{-i (s_1 + s_2 - s_1 s_2) H t} (1-s_1) ds_1 ds_2 ~ \rho(t) \\
    &= -t^2 \int_0^1 \int_0^1 G(s_1 t) G((s_1 + s_2 - s_1 s_2)t) (1-s_1) ds_1 ds_2 ~ \rho(t)
\end{align}

\begin{align}
    (C) &= it \int_0^1 e^{i s (H + \alpha G)t} G e^{i(1-s) (H + \alpha G) t} ds ~\rho ~ \frac{\partial}{\partial \alpha} \parens{ e^{-i (H + \alpha G) t} } \bigg|_{\alpha = 0} \\
    &= (i t) (-it) \int_0^1 e^{i s (H + \alpha G)t} G e^{i (1 - s) (H + \alpha G)t} ds ~ \rho ~ \parens{ \int_0^1 e^{-i s (H + \alpha G)t} G e^{-i (1- s) ( H + \alpha G)t } ds}\bigg|_{\alpha = 0} \\
    &= + t^2 \parens{\int_0^1 e^{i s H t} G e^{-i s H t} ds} e^{i H t} \rho e^{-i H t} \parens{\int_0^1 e^{i (1-s) H t} G e^{-i (1-s) H t} ds} \\
    &= + t^2 \int_0^1 G(st) ds ~ \rho(t) \int_0^1 G((1-s)t) ds
\end{align}

\begin{align}
    (D) &= (-it) \frac{\partial}{\partial \alpha} \parens{e^{i(H + \alpha G)t}} \rho \int_0^1 e^{-i s (H + \alpha G)t} G e^{-i (1-s)(H + \alpha G)t} ds \bigg|_{\alpha = 0} \\
    &= t^2 \parens{\int_0^1 e^{i s (H+ \alpha G)t} G e^{i (1-s) (H + \alpha G)t}ds} \rho \int_0^1 e^{-i s (H + \alpha G)t} G e^{-i (1-s)(H + \alpha G)t} ds \bigg|_{\alpha = 0} \\
    &=  t^2 \int_0^1 e^{i s H t} G e^{-i s H t} ds ~\rho(t) \int_0^1 e^{i (1-s) H t} G e^{-i (1-s) H t} ds \\
    &= t^2 \int_0^1 G(st) ds ~ \rho(t) ~ \int_0^1 G((1-s)t) ds
\end{align}

\begin{align}
    (E) &= (-it) e^{i (H+ \alpha G) t} ~ \rho ~\int_0^1 \frac{\partial}{\partial \alpha} \parens{e^{-i s_1 (H + \alpha G)t}} G e^{-i (1-s_1)(H + \alpha G)t} ds_1 \bigg|_{\alpha = 0} \\
    &= - t^2 e^{i(H + \alpha G)t} ~ \rho ~\int_0^1 \parens{\int_0^1 e^{-i s_1 s_2 (H + \alpha G) t} (s_1 G) e^{-i s_1 (1-s_2) (H + \alpha G)t} ds_2} G e^{-i(1-s_1)(H + \alpha G)t} ds_1 \bigg|_{\alpha = 0} \\
    &= -t^2 e^{i H t} \rho e^{-i H t} \int_0^1 \int_0^1 e^{i (1 - s_1 s_2) H t} G e^{-i (s_1 - s_1 s_2)H t} G e^{-i (1-s_1)H t} s_1 ds_1 ds_2 \\
    &= -t^2 \rho(t) \int_0^1 \int_0^1 G((1- s_1 s_2) t) G((1-s_1)t) s_1 ds_1 ds_2
\end{align}

\begin{align}
    (F) &= (-it) e^{i(H + \alpha G) t} \rho \int_0^1 e^{-i s_1 ( H + \alpha G) t} G \frac{\partial}{\partial \alpha} \parens{ e^{-i (1-s_1) ( H +\alpha G)t}} ds_1 \bigg|_{\alpha = 0} \\
    &= (-it)^2 e^{i (H + \alpha G)t} \rho \int_0^1 e^{-i s_1 (H + \alpha G)t} G \parens{\int_0^1 e^{-i(1-s_1) s_2 (H + \alpha G)t} (1-s_1) G e^{-i(1-s_1) (1-s_2) (H + \alpha G) t} ds_2} ds_1 \bigg|_{\alpha = 0} \\
    &= -t^2 e^{-i H t} \rho e^{-i H t} \int_0^1 \int_0^1 e^{i (1- s_1) H t} G e^{-i (1-s_1) H t} e^{i (1-s_1)(1-s_2) H t} G e^{-i(1-s_1)(1-s_2) H t} (1-s_1) ds_1 ds_2 \\
    &= -t^2 \rho(t) \int_0^1 \int_0^1 G((1-s_1)t) G((1-s_1)(1 - s_2) t) (1-s_1)ds_1 ds_2
\end{align}

Now our goal is to compute the effects of averaging over the interaction $G$ on the above terms, starting with $(A)$. As this involves a lot of index manipulations, similarly to the proofs of Lemmas \ref{lem:two_heisenberg_interactions} and \ref{lem:sandwiched_interaction} we will use a single index for the total system-environment Hilbert space and switch back to a double index to state the results. We will make heavy use of Lemma \ref{lem:two_heisenberg_interactions}.
\begin{align}
    \int (A) dG &= -t^2 \int_0^1 \int_0^1 \int G(s_1 s_2 t) G(s_1 t) dG s_1 ds_1 ds_2 \rho(t) \\
    &= \frac{-t^2 }{\dim + 1} \int_0^1 \int_0^1 \parens{\sum_{i,j} e^{i (\lambda(i) - \lambda(j)) (s_1 s_2 t - s_1 t)} \ketbra{i}{i} + \identity} s_1 ds_1 ds_2 \rho(t) \\
    &= \frac{- t^2 }{\dim + 1} \parens{\sum_{i} \sum_{j : \lambda(i) \neq \lambda(j)} \int_0^1 \int_0^1 e^{i(\lambda(i) - \lambda(j))t (s_1 s_2 - s_1)} s_1 ds_1 ds_2 \ketbra{i}{i} + \sum_{i} \sum_{j : \lambda(i) = \lambda(j)}\frac{1}{2} \ketbra{i}{i} + \frac{1}{2} \identity} \rho(t) \\
    &= \frac{- t^2 }{\dim + 1} \parens{\sum_i \sum_{j : \lambda(i) \neq \lambda(j)} \frac{1 - i (\lambda(i) - \lambda(j))t - e^{-i (\lambda(i) - \lambda(j))t}}{t^2 (\lambda(i) - \lambda(j))^2} \ketbra{i}{i} + \frac{1}{2} \sum_{i} (\eta(i) + 1) \ketbra{i}{i} } \rho(t) \\
    &= \frac{- 1}{\dim + 1}\parens{\sum_{i} \sum_{j: \Delta_{ij} \neq 0} \frac{1 - i \Delta_{ij}t - e^{-i \Delta_{ij} t}}{\Delta_{ij}^2} \ketbra{i}{i} + \frac{t^2}{2} \sum_{i} (\eta(i) + 1)\ketbra{i}{i} } \rho(t)
\end{align}

We can similarly compute the averaged $(B)$ term:
\begin{align}
    \int (B) dG &= -t^2 \int_0^1 \int_0^1 \int G(s_1 t) G((s_1 + s_2 - s_1 s_2) t) dG (1-s_1) ds_1 ds_2 ~ \rho(t) \\
    &= \frac{- t^2 }{\dim + 1} \int_0^1 \int_0^1 \parens{\sum_{i,j} e^{i (\lambda(i) - \lambda(j))(s_1 s_2 - s_2) t} \ketbra{i}{i} + \identity} (1 -s_1) ds_1 ds_2 \rho \\
    &= \frac{- t^2 }{\dim + 1} \parens{\sum_{i} \sum_{j : \lambda(i) \neq \lambda(j)} \int_0^1 \int_0^1 e^{i(\lambda(i) - \lambda(j))t (s_1 s_2 - s_2)} (1 - s_1) ds_1 ds_2 \ketbra{i}{i} + \sum_{i} \sum_{j : \lambda(i) = \lambda(j)}\frac{1}{2} \ketbra{i}{i} + \frac{1}{2} \identity} \rho(t) \\
    &= \frac{- t^2 }{\dim + 1} \parens{\sum_i \sum_{j : \lambda(i) \neq \lambda(j)} \frac{1 - i (\lambda(i) - \lambda(j))t - e^{-i (\lambda(i) - \lambda(j))t}}{t^2 (\lambda(i) - \lambda(j))^2} \ketbra{i}{i} + \frac{1}{2} \sum_{i} (\eta(i) + 1) \ketbra{i}{i} } \rho(t) \\
    &= \frac{-1}{\dim + 1}\parens{\sum_{i} \sum_{j: \Delta_{ij} \neq 0} \frac{1 - i \Delta_{ij}t - e^{-i \Delta_{ij} t}}{\Delta_{ij}^2} \ketbra{i}{i} + \frac{t^2}{2} \sum_{i} (\eta(i) + 1)\ketbra{i}{i} } \rho(t),
\end{align}
which we note is identical to $\int (A) dG$. As terms $(C)$ and $(D)$ involve a different method of computation we skip them for now and compute $(E)$ and $(F)$. 
\begin{align}
    \int (E) dG &= -t^2 \rho(t) \int_0^1 \int_0^1 \int G((1- s_1 s_2) t) G((1-s_1)t) dG s_1 ds_1 ds_2 \\
    &= \frac{- t^2}{\dim + 1} \rho(t) \int_0^1 \int_0^1 \parens{\sum_{i,j} e^{i(\lambda(i) - \lambda(j)) t (s_1 - s_1 s_2)} \ketbra{i}{i} + \identity } s_1 ds_1 ds_2 \\
    &= \frac{- t^2}{\dim + 1} \rho(t) \parens{\sum_i \sum_{j : \lambda(i) \neq \lambda(j)} \frac{1 + i (\lambda(i) - \lambda(j))t - e^{i(\lambda(i) - \lambda(j))t}}{t^2 (\lambda(i) - \lambda(j))^2}\ketbra{i}{i} + \frac{1}{2} \sum_{i} (\eta(i) + 1 )\ketbra{i}{i}} \\
    &= \frac{- 1}{\dim + 1} \rho(t) \parens{\sum_i \sum_{j: (\Delta_{ij} \neq 0)} \frac{1 + i \Delta_{ij}t - e^{i\Delta_{ij}t}}{\Delta_{ij}^2} \ketbra{i}{i} + \frac{t^2}{2}\sum_i (\eta(i) + 1) \ketbra{i}{i}}.
\end{align}
Computing $(F)$ yields
\begin{align}
    \int (F) dG &= -t^2 \rho(t) \int_0^1 \int_0^1 \int G((1-s_1)t) G((1-s_1)(1 - s_2) t) dG (1-s_1)ds_1 ds_2 \\
    &= \frac{- t^2 \sigma ^2}{\dim + 1} \rho(t) \int_0^1 \int_0^1 \parens{\sum_{i,j} e^{i(\lambda(i) - \lambda(j))t (s_2 - s_1 s_2)}\ketbra{i}{i} + \identity} (1-s_1) ds_1 ds_2 \\
    &= \frac{- t^2 }{\dim + 1} \rho(t) \parens{\sum_{i} \sum_{j : \lambda(i) \neq \lambda(j)} \frac{1 + i (\lambda(i) - \lambda(j))t - e^{i (\lambda(i) - \lambda(j))t}}{t^2 (\lambda(i) - \lambda(j))^2} \ketbra{i}{i} +\frac{1}{2} \sum_{i} (\eta(i) + 1) \ketbra{i}{i}} \\
    &= \frac{- 1}{\dim + 1} \rho(t) \parens{\sum_i \sum_{j: (\Delta_{ij} \neq 0)} \frac{1 + i \Delta_{ij}t - e^{i\Delta_{ij}t}}{\Delta_{ij}^2} \ketbra{i}{i} + \frac{t^2}{2}\sum_i (\eta(i) + 1) \ketbra{i}{i}}
\end{align}
 which is identical to $\int (E) dG$.

 The last two terms $(C) = (D)$ are computed as follows:
 \begin{align}
     \int (C) dG &= t^2 \int_0^1 \int_0^1 \int G(s_1 t) \rho(t) G((1-s_2)t) ~dG ~ ds_1 ds_2 \\
     &= t^2 \sum_{i,j} \rho_{ij} e^{i(\lambda(i) - \lambda(j))t} \int_0^1 \int_0^1 \int G(s_1 t) \ketbra{i}{j} G((1-s_2)t) ~ dG ~ ds_1 ds_2 \\
     &= \frac{ t^2}{\dim + 1} \sum_{i,j} \rho_{ij} e^{i(\lambda(i) - \lambda(j))t} \parens{ \ketbra{i}{j} + \delta_{ij} \sum_{a} \int_0^1 \int_0^1 e^{i(\lambda(a) - \lambda(i))(s_1 + s_2 - 1)t} ds_1 ds_2 \ketbra{a}{a}} \\
     &= \frac{ t^2}{\dim + 1} \sum_{i,j} \rho_{ij} e^{i \Delta_{ij} t} \parens{\ketbra{i}{j} + \delta_{ij} \sum_{a : \Delta_{ai} \neq 0} \frac{2( 1- \cos (\Delta_{ai} t))}{\Delta_{ai}^2 t^2} \ketbra{a}{a} + \delta_{ij} \sum_{a : \Delta_{ai} = 0} \ketbra{a}{a}}
 \end{align}

 We can now combine each of these terms to offer the full picture of the output of the channel to second order. We make two modifications to the results from each sum: first, we will switch to double index notation to make for easier use in other areas, and secondly we let $\rho = \ketbra{i,j}{k,l}$. We note that the first term in the following equation is provided by $(A) + (B)$, the second through $(E) + (F)$, and the last two through $(C) + (D)$. 
 \begin{align}
     &\int \frac{\partial^2}{\partial \alpha^2} \Phi_G(\ketbra{i,j}{k,l})\bigg|_{\alpha = 0} dG \\
     &= -\frac{2  e^{i \Delta(i,j|k,l) t}}{\dim + 1} \bigg(\sum_{(a,b): \Delta(i,j|a,b) \neq 0} \frac{1 - i \Delta(i,j|a,b)t - e^{-i \Delta(i,j|a,b) t}}{\Delta(i,j|a,b)^2} \nonumber \\
     &~+ \sum_{(a,b): \Delta(k,l|a,b) \neq 0} \frac{1 + i \Delta(k,l|a,b) t - e^{i \Delta(k,l|a,b) t}}{\Delta(k,l|a,b)^2} + \frac{t^2}{2}(\eta(i,j) + \eta(k,l)) \bigg) \ketbra{i,j}{k,l} \nonumber \\
    &~ +\delta_{i,k} \delta_{j,l} \frac{2 e^{i \Delta(i,j|k,l)t}}{\dim+1} \parens{ \sum_{(a,b): \Delta(i,j|a,b) \neq 0 } \frac{2(1- \cos (\Delta(i,j|a,b)t))}{\Delta(i,j|a,b)^2} \ketbra{a,b}{a,b} + t^2 \sum_{(a,b) : \Delta(i,j|a,b) = 0} \ketbra{a,b}{a,b}} \label{eq:second_order_output}
 \end{align}
\end{proof}

The goal for the remainder of this section is to simplify the expression for the channel output given by the above lemma. The first thing to note is that our channel does not appear to have large off-diagonal contributions to second order in $\alpha$. 
\begin{corollary}
    Given the inputs to Lemma \ref{lem:the_double_duhamel} and a diagonal input state $\rho = \sum_{i,j} \rho_{i,j} \ketbra{i,j}{i,j}$, then we have $$\bra{k,l}  \int \Phi_G(\rho) ~dG~ \ket{m,n} \in \bigo{\alpha^3},$$ for $(k,l) \neq (m,n)$.
\end{corollary}
\begin{proof}
    We start from the Taylor's series of $\Phi_G$ with respect to $\alpha$:
    \begin{equation}
        \Phi_G(\rho) = \rho + \frac{\alpha^2}{2!} \int \frac{\partial^2}{\partial \alpha^2} \Phi_G(\rho) dG + \bigo{\alpha^3}. \label{eq:off_diagonal_taylors}
    \end{equation}
    First we note that $\bra{k,l}\rho \ket{m,n} =0$, as $\rho$ is diagonal and we assumed that $(k,l) \neq (m,n)$. Substituting Lemma \ref{lem:the_double_duhamel} for the second order derivative and taking matrix elements yields:
    \begin{align}
        &\bra{k,l} \int \frac{\partial^2}{\partial \alpha^2} \Phi_G(\rho)\bigg|_{\alpha = 0} dG ~dG ~\ket{m,n}  \\
     &= -\frac{2 }{\dim + 1} \bigg(\sum_{(a,b): \Delta(i,j|a,b) \neq 0} \frac{1 - i \Delta(i,j|a,b)t - e^{-i \Delta(i,j|a,b) t}}{\Delta(i,j|a,b)^2} \nonumber \\
     &~+ \sum_{(a,b): \Delta(k,l|a,b) \neq 0} \frac{1 + i \Delta(k,l|a,b) t - e^{i \Delta(k,l|a,b) t}}{\Delta(k,l|a,b)^2} + \frac{t^2}{2}(\eta(i,j) + \eta(k,l)) \bigg) \bra{k,l} \rho \ket{m,n} \nonumber \\
    &~ + \frac{2}{\dim+1}\sum_{i,j} \rho_{i,j} \bigg(\sum_{(a,b): \Delta(i,j|a,b) \neq 0 } \frac{2(1- \cos (\Delta(i,j|a,b)t))}{\Delta(i,j|a,b)^2} \braket{k,l}{a,b} \braket{a,b}{m,n} \nonumber \\
    &~ + t^2 \sum_{(a,b) : \Delta(i,j|a,b) = 0} \braket{k,l}{a,b} \braket{a,b}{m,n} \bigg).
    \end{align}
    We see that the factors $\bra{k,l}\rho \ket{m,n}$ and $\braket{k,l}{i,j} \braket{i,j}{m,n}$ can never be non-zero due to the assumption $(k,l) \neq (m,n)$. The only remaining term in Eq. \ref{eq:off_diagonal_taylors} is of $\bigo{\alpha^3}$, yielding the stated result.
\end{proof}

Our last objective in this section is to yield a (relatively) concise statement for transition probabilities among diagonal matrix elements for density matrices. As we will be interested in computing trace distances we will be interested in 
\begin{theorem} \label{thm:second_order_transition_coeffs}
Given the inputs to Lemma \ref{lem:the_double_duhamel}, let 
$$\tau(i,j | k,l) \coloneqq \frac{\alpha^2 }{2} \bra{k,l} \int \frac{\partial^2}{\partial \alpha^2} \Phi_G(\ketbra{i,j}{i,j})\bigg|_{\alpha = 0} dG \ket{k,l},$$ denote the second order transition coefficients in $\alpha$. These are expressed in terms of the eigenvalue differences $\Delta(i',j'|k',l')$ and other constants as 
$$\tau(i,j | k,l) = \begin{cases}
    - \frac{\alpha^2}{\dim + 1} \parens{\sum_{(a,b) : \Delta(i,j | a,b) \neq 0} \frac{2(1- \cos(\Delta(a,b | i,j)t)}{\Delta(a,b |i,j)^2} + t^2 (\eta(i,j) - 1)} & (i,j) = (k,l) \\
    \frac{\alpha^2 t^2}{\dim + 1} & (i,j) \neq (k,l), \Delta(i,j | k,l) = 0 \\
    \frac{2 \alpha^2}{\dim + 1} \frac{1 - \cos(\Delta(i,j | k,l) t)}{\Delta(i,j | k,l)^2} & \Delta(i,j| k,l) \neq 0.
\end{cases}$$
. A summation shows that $\tau(i,j|i,j) = -\sum_{(k,l) \neq (i,j)} \tau(i,j|k,l)$, which as a byproduct shows that the mapping $\Phi$ is trace preserving to order $\bigo{\alpha^2}$. Further we note that 
\begin{align}
    \frac{2(1 - \cos(\Delta t)}{\Delta^2} &= \frac{2(1 - \cos^2(\Delta t / 2) + \sin^2(\Delta t /2)}{\Delta^2} \\
    &= \frac{t^2}{2} \frac{\sin^2 (\Delta t / 2)}{ (\Delta t/ 2)^2} \\
    &= \frac{t^2}{2} \sinc^2(\Delta t /2).
\end{align}
\end{theorem}
\begin{proof}
    We focus exclusively on diagonal inputs and outputs for density matrices, $\ketbra{a}{a}$ and $\ketbra{b}{b}$. We use Eq. \eqref{eq:second_order_output}, starting with transitions within the degenerate subspace of $a$. For the following we assume $a \neq b$ and $\Delta_{ab} = 0$: 
    \begin{align}
        &\prob{a \to b | a \neq b, \Delta_{ab} = 0} = \trace{\ketbra{b}{b} \int \Phi_G(\ketbra{a}{a}) dG} \\
        &= \braket{b}{a} \braket{a}{b} + \frac{\alpha^2}{2} \bra{b} \int \frac{\partial^2}{\partial \alpha^2} \Phi_G(\ketbra{a}{a})\bigg|_{\alpha = 0} dG \ket{b} \\
        &= -\frac{\sigma^2 \alpha^2}{\dim + 1} \bigg(\sum_{j: \Delta_{aj} \neq 0} \frac{1 - i \Delta_{aj}t - e^{-i \Delta_{aj} t}}{\Delta_{aj}^2} + \sum_{j: \Delta_{aj} \neq 0} \frac{1 + i \Delta_{aj} t - e^{i \Delta_{aj} t}}{\Delta_{aj}^2} + t^2 \eta(a) \bigg) \braket{b}{a} \braket{a}{b} \nonumber \\
        &~+ \frac{\alpha^2 \sigma^2}{\dim + 1} \parens{\sum_{i: \Delta_{ai} \neq 0} \frac{2(1- \cos(\Delta_{ai} t)}{\Delta_{ai}^2} \braket{b}{i}\braket{i}{b} + t^2 \sum_{i: \Delta_{ai} = 0 } \braket{b}{i} \braket{i}{b}} \label{eq:transition_intermediate} \\
        &= \frac{\sigma^2 \alpha^2 t^2}{\dim + 1}. 
    \end{align}
    We now proceed to the case that $b \neq a$ and $\Delta_{ab} \neq 0$, where we can start from Eq. \eqref{eq:transition_intermediate} and we get
    \begin{equation}
        \prob{a \to b | a \neq b, \Delta_{ab} \neq 0} = \frac{2 \sigma^2 \alpha^2 }{\dim + 1} \frac{1 - \cos (\Delta_{ab} t)}{\Delta_{ab}^2}.
    \end{equation}

    The remaining case to consider is when $b = a$. This involves simplifying the summations in Eq. \eqref{eq:second_order_output} and including the zeroth order $\bigo{\alpha^0}$ term which simply contributes a 1. 
    \begin{align}
        \prob{a \to a} &= 1 -\frac{\sigma^2 \alpha^2 }{\dim + 1} \bigg(\sum_{j: \Delta_{aj} \neq 0} \frac{1 - i \Delta_{aj}t - e^{-i \Delta_{aj} t}}{\Delta_{aj}^2} + \sum_{j: \Delta_{aj} \neq 0} \frac{1 + i \Delta_{aj} t - e^{i \Delta_{aj} t}}{\Delta_{aj}^2} + t^2 \eta(a) \bigg) \nonumber \\
    &~ +\frac{\sigma^2 \alpha^2 }{\dim+1} \parens{ \sum_{i: \Delta_{ai} \neq 0 } \frac{2(1- \cos (\Delta_{ai}t))}{\Delta_{ai}^2} \braket{a}{i} \braket{i}{a} + t^2  \sum_{i : \Delta_{ai} = 0} \braket{a}{i} \braket{i}{a}} \\
    &= 1 - \frac{\sigma^2 \alpha^2}{\dim + 1} \parens{\sum_{i: \Delta_{ai} \neq 0} \frac{2(1 - \cos(\Delta_{ai}t))}{\Delta_{ai}^2} + t^2 (\eta(a) - 1)}.
    \end{align}
    This completes the transition probability computation. It is straightforward to see that $\sum_{b} \prob{a \to b} = 1$ and that $0 \leq \prob{a \to b} \leq 1$ given that $t^2 \leq \frac{\dim + 1}{\alpha^2 \sigma^2}$.
\end{proof}

\section{Single Qubit System \& Environment}
We now will analyze the effects of $\Phi$ on thermalizing a system state with only a single qubit environment. The single qubit case makes the effect of tracing out the environment tractable. For absolute simplicity, we first study the case of two qubits. After this situation is analyzed in detail we extend the results to arbitrary system Hamiltonians. For the remainder of this section we assume a a system Hamiltonian $H_S = \begin{bmatrix}
    0 & 0 \\ 0 & \Delta_S
\end{bmatrix}$ and an environment Hamiltonian $H_E = \begin{bmatrix}
    0 & 0 \\ 0 & \gamma
\end{bmatrix}$. Further we will use an environment prepared in the state $\rho_E(\beta) = \frac{e^{-\beta H_E}}{\partfun_E(\beta)}$. Another restriction we will make is that we assume that $t \geq \frac{2}{\Delta_{\min} \sqrt{\epsilon_{\sinc}}}$, where $\lambda(i,j) = \lambda(k,l)$ or $\lambda(i,j) - \lambda(k,l) \geq \Delta_{\min}$, per Lemma \ref{lem:sinc_poly_approx}. 

Given the two qubit setup as mentioned, we want to compute the trace distance 
\begin{equation}
    \norm{\rho_S(\beta) - \Phi(\rho_S(\beta))}_1.
\end{equation}
We first start with the trace distance and reduce it to a computation of transition coefficients. 
\begin{align}
    \norm{\rho_S(\beta) - \Phi(\rho_S(\beta))}_1  &= \norm{\frac{\alpha^2}{2} \partrace{\hilb_E}{\int \frac{\partial^2}{\partial \alpha^2} \Phi_G(\rho_S(\beta) \otimes \rho_E(\beta)) \bigg|_{\alpha = 0} ~dG}}_1 + \bigo{\alpha^3} \\
    &\approx \norm{\sum_{i,j} e^{-\beta \lambda(i,j)} \partfun(\beta)^{-1}\partrace{\hilb_E}{ \frac{\alpha^2}{2} \int \frac{\partial^2}{\partial \alpha^2} \Phi_G(\ketbra{i,j}{i,j})\bigg|_{\alpha=0} dG} }_1 \\
    &= \norm{\sum_{i,j} e^{-\beta \lambda(i,j)} \partfun(\beta)^{-1} \partrace{\hilb_E}{\sum_{k,l} \tau(i,j | k,l) \ketbra{k,l}{k,l}}}_1 \\
    &= \norm{\sum_{i,j} e^{-\beta \lambda(i,j)} \partfun(\beta)^{-1} \sum_{k,l} \tau(i,j |k,l) \ketbra{k}{k}}_1 \\
    &= \sum_k \abs{\sum_{i,j} e^{-\beta \lambda(i,j)} \partfun(\beta)^{-1} \sum_{l} \tau(i,j |k,l)} \\
    &= \frac{1}{|\partfun(\beta)|} \sum_k \abs{\sum_{i,j} e^{-\beta \lambda(i,j)} \sum_{l} \tau(i,j |k,l)} \label{eq:fixed_point_as_transition_coeffs}
\end{align}
\begin{align}
&\norm{\rho_S(\beta_E) - \Phi(\rho_S(\beta))}_p^p \\
&= \norm{\rho_S(\beta_E) - \rho_S(\beta) - \frac{\alpha^2}{2} \partrace{\hilb_E}{\int \frac{\partial^2}{\partial \alpha^2} \Phi_G(\rho_S(\beta) \otimes \rho_E(\beta_E)) \bigg|_{\alpha=0} dG}}_p^p + \bigo{\alpha^3} \\
&\approx \norm{\rho_S(\beta_E) - \rho_S(\beta) - \sum_{i,j} \frac{e^{-\beta \lambda_S(i) -\beta_E \lambda_E(j)}}{\partfun_S(\beta) \partfun_E(\beta_E)} \frac{\alpha^2}{2}\partrace{\hilb_E}{\int \frac{\partial^2}{\partial \alpha^2} \Phi_G(\ketbra{i,j}{i,j}) \bigg|_{\alpha=0} dG} }_p^p \\
&= \norm{\rho_S(\beta_E) - \rho_S(\beta) - \sum_{i,j} \frac{e^{-\beta \lambda_S(i) -\beta_E \lambda_E(j)}}{\partfun_S(\beta) \partfun_E(\beta_E)} \partrace{\hilb_E}{\sum_{k,l} \tau(i,j|k,l) \ketbra{k,l}{k,l}} }_p^p \\
&= \norm{\rho_S(\beta_E) - \rho_S(\beta) - \sum_{i,j} \sum_{k,l} \frac{e^{-\beta \lambda_S(i) -\beta_E \lambda_E(j)}}{\partfun_S(\beta) \partfun_E(\beta_E)} \tau(i,j|k,l) \ketbra{k}{k} }_p^p \\
&= \sum_k \abs{\frac{e^{-\beta_E \lambda_S(k)}}{\partfun_S(\beta_E)} - \frac{e^{-\beta \lambda_S(k)}}{\partfun_S(\beta)} - \sum_{i,j,l} \frac{e^{-\beta \lambda_S(i) - \beta_E \lambda_E(j)}}{\partfun_S(\beta) \partfun_E(\beta_E)} \tau(i,j|k,l)}^p. \label{eq:trace_dist_p_norm}
\end{align}
We note that the last step is due to the fact that $\rho_S(x)$ is diagonal in the eigenbasis that we are working over. We drop the $\bigo{\alpha^3}$ term, we could possibly upper bound it by some additional error contribution $\epsilon_{\alpha}$ or by stating that since it is less than the $\alpha^2$ contribution we could simply add a factor of 2 in front of the norm. These details should be cleaned up. Our goal is to now compute these sums for fixed $k$ in 0,1.

\subsection{Fixed Points}

In the following we set $p=1$ and $\beta = \beta_E$.
    We make heavy use of Lemma \ref{thm:second_order_transition_coeffs}. 
    We now compute the term for $k=0, i=1$
    \begin{align}
        \sum_{j, l} e^{-\beta \lambda(1,j)} \tau(1,j| 0, l) &=  e^{-\beta \Delta_S} \parens{\tau(1, 0| 0, 0) + \tau(1, 0 | 0, 1)} +  e^{-\beta (\Delta_S + \gamma)} \parens{\tau(1, 1 | 0, 0) + \tau(1, 1| 0, 1)} \label{eq:single_qubit_fixed_pt_1} 
    \end{align}
    Now we compute the term for $k=0, i= 0$, which involves using the self-transition substitution for $\tau(a,b|a,b)$.
    \begin{align}
        \sum_{j,l} e^{-\beta \lambda(0,j)} \tau(0,j|0,l) &= e^{-\beta \cdot 0} \parens{\tau(0,0| 0,0) + \tau(0,0 | 0,1)} + e^{-\beta \gamma} \parens{\tau(0,1 | 0,0) + \tau(0,1|0,1)} \\
        &= -(\tau(0,0| 0,1) + \tau(0,0| 1,0) + \tau(0,0|1,1)) + \tau(0,0|0,1) \nonumber \\
        &~ + e^{-\beta \gamma} \parens{\tau(0,1|0,0) - (\tau(0,1|0,0) + \tau(0,1| 1,0) + \tau(0,1|1,1))} \\
        &= - \tau(0,0|1,0)  - \tau(0,0|1,1) - e^{-\beta \gamma} \tau(0,1|1,0) - e^{-\beta \gamma} \tau(0,1|1,1) \label{eq:single_qubit_fixed_pt_2}
    \end{align}
    Using the fact that $\tau(a,b|c,d) = \tau(c,d|a,b)$ we can add Eqs. \ref{eq:single_qubit_fixed_pt_1} and \ref{eq:single_qubit_fixed_pt_2} to get:
    \begin{align}
        \sum_{i,j} e^{-\beta \lambda(i,j)} \sum_l \tau(i,j|0,l) &= \tau(0,0|1,0)(e^{-\beta \Delta_S} -1) + \tau(0,1|1,0)(e^{-\beta \Delta_S} - e^{-\beta \gamma}) \nonumber \\
        &\quad + \tau(0,0,| 1,1) (e^{-\beta (\Delta_S + \gamma)} - 1) + \tau(0,1|1,1) (e^{-\beta (\Delta_S + \gamma)} - e^{-\beta \gamma})
    \end{align}
    We can now use the fact that $\tau(a,b|c,d)$ is positive for $(a,b) \neq (c,d)$ and that $\beta > 0, \Delta_S > 0$ and $\gamma > 0$ to rewrite the above as
    \begin{align}
        \sum_{i,j} e^{-\beta \lambda(i,j)} \sum_l \tau(i,j|0,l) &= \tau(0,1|1,0)(e^{-\beta \Delta_S} - e^{-\beta \gamma}) - \tau(0,0|1,0)(1 - e^{-\beta \Delta_S})  \nonumber \\
        &\quad - \tau(0,0,| 1,1) (1 - e^{-\beta (\Delta_S + \gamma)}) - \tau(0,1|1,1) e^{-\beta \gamma} (1 - e^{-\beta \Delta_S})
    \end{align}
    Now using the intution that non-degenerate transitions are going to be significantly suppressed, we use the triangle inequality. 
    \begin{align}
        &\bigg| \tau(0,1|1,0)(e^{-\beta \Delta_S} - e^{-\beta \gamma}) - \tau(0,0|1,0)(1 - e^{-\beta \Delta_S})  \nonumber \\
        &\quad - \tau(0,0,| 1,1) (1 - e^{-\beta (\Delta_S + \gamma)}) - \tau(0,1|1,1) e^{-\beta \gamma} (1 - e^{-\beta \Delta_S})\bigg| \\
        &\leq \abs{\tau(0,1|1,0) (e^{-\beta \Delta_S} - e^{-\beta \gamma})} + \abs{\tau(0,0|1,0)} + |\tau(0,0|1,1)| + |\tau(0,1|1,1)| \\
        &\leq \abs{\tau(0,1|1,0) (e^{-\beta \Delta_S} - e^{-\beta \gamma})} + 3 \frac{\epsilon_{\sinc} \alpha^2 t^2}{2(\dim + 1)} \\
        &= \frac{\alpha^2 t^2}{2(\dim + 1)} \parens{\sinc^2((\Delta_S - \gamma)t/2) |e^{-\beta \Delta_S} - e^{-\beta \gamma}| + 3 \epsilon_{\sinc}}\\
        &= \frac{\alpha^2 t^2}{2 (\dim + 1)} \parens{\sinc^2((\Delta_S - \gamma)t/2) e^{-\beta \Delta_S} |1 - e^{\beta (\Delta_S - \gamma)}| + 3 \epsilon_{\sinc}} \\
        &=: \frac{\alpha^2 t^2}{2(\dim + 1)} (e^{-\beta \Delta_S} g(\Delta_S - \gamma) + 3 \epsilon_{\sinc})
    \end{align}

    Now when computing the summation $|\sum_{i,j} e^{-\beta \lambda(i,j)} \sum_l \tau(i,j |1,l)|$, for $k=1$, the same result as $k=0$ is found. This allows us to say that the trace distance is upper bounded by
    \begin{equation}
        \norm{\rho_S(\beta) - \Phi(\rho_S(\beta))}_1 \leq \frac{\alpha^2 t^2}{(\dim + 1)\partfun} (e^{-\beta \Delta_S} g(\Delta_S - \gamma) + 3 \epsilon_{\sinc}).
    \end{equation}
    We note that the following upper bound is sufficient to show that the trace distance is bounded:
    \begin{align}
        g(\Delta_S - \gamma) &= \sinc^2((\Delta_S - \gamma)t/2) \abs{1 - e^{\beta(\Delta_S - \gamma)}} \\
        &\leq \abs{e^{\beta(\Delta_S - \gamma)} - 1} \\
        &\leq e^{\beta \Delta_S} - 1,
    \end{align}
    where we assumed $\gamma \geq 0$ in the last step. This yields the following upper bound on the trace distance
    \begin{equation}
        \norm{\rho_S(\beta) - \Phi(\rho_S(\beta))}_1 \leq \frac{\alpha^2 t^2}{\partfun (\dim+1)} (1 - e^{-\beta \Delta_S} + 3 \epsilon_{\sinc}).
    \end{equation}
    We can even drop the $e^{-\beta \Delta_S}$ term and have 
    $$\alpha^2 \leq \epsilon_{\beta} \frac{ \partfun (\dim + 1)}{t^2 (1 - e^{-\beta \Delta_S} + 3 \epsilon_{\sinc})}$$
    to imply $\norm{\rho_S(\beta) - \Phi(\rho_S(\beta))}_1 \leq \epsilon_{\beta}$.

    This is not the complete picture, however. We also have to satisfy the inequality $\alpha^2 t^2 / (\dim + 1) \leq 1$ in order for $\tau$ to represent valid transition probabilities. 


    Another weird thing is that as $\gamma \to \Delta_S$, aka we have a degenerate transition possible, it seems that the contribution of this transition to the trace distance vanishes? If you look at the temperature contributions we have $\tau(0,1|1,0)|e^{-\beta \Delta_S} - e^{-\beta \gamma}|$, which goes to zero as $\gamma \to \Delta_S$. This is seemingly contradictory, as we are getting probability mass shuffling between the energy levels. 
    
    Our goal is to produce an upper bound on $g(\Delta_S - \gamma)$. To do so there are two different approaches we explore. The first is to sample $\gamma$ from a probability distribution and look at the expected value of the trace distance. The easiest distribution to start with is a uniform distribution from $\Delta_S - \frac{1}{2} \epsilon \Delta_{\text{min}}$ to $\Delta_S + \frac{1}{2} \epsilon \Delta_{\text{min}}$. Within this range we can approximate $\sinc^2 ((\Delta_S - \gamma)t/2)$ as $1$ with only an error of at most $\epsilon$. 
    \begin{align}
        \int_{\Delta_S - \epsilon \Delta_{\text{min}}/2}^{\Delta_S + \epsilon \Delta_{\text{min}}/2} g(\Delta_S - \gamma) \prob{\gamma} d\gamma &= \int_{\epsilon \Delta_{\text{min}}/2}^{-\epsilon \Delta_{\text{min}}/2} g(u) \prob{u(\gamma)} (-du) \\
        &=\frac{1}{\epsilon \Delta_{\text{min}}} \int_{-\epsilon \Delta_{\text{min}}/2}^{\epsilon \Delta_{\text{min}}/2} \sinc^2(u t /2) |1 - e^{\beta u}| du \\
        &\leq  \parens{\frac{1}{\epsilon \Delta_{\text{min}}} \int_{-\epsilon \Delta_{\text{min}}/2}^{\epsilon \Delta_{\text{min}}/2} |1 - \epsilon| |1 - e^{\beta u}| du + 3 \epsilon_{\sinc}} \\
        &= \parens{\frac{1}{ \Delta_{\text{min}}} \parens{\frac{1}{\epsilon } - 1}\frac{2(\cosh (\beta \epsilon \Delta_{\text{min}}/2) - 1)  }{\beta} + 3 \epsilon_{\sinc}}
    \end{align}
    We see that in the limit as $\epsilon \to 0$, $\cosh(\beta \epsilon \Delta_{\min} /2) - 1 \in \bigo{\epsilon^2}$, so the total contribution is of order $\bigo{\epsilon}$. Similar logic holds for the limit as $\Delta_{\min} \to 0$. As $\beta \to \infty$, the $\cosh$ term simply approaches an exponential $e^{\beta \epsilon \Delta_{\min} /2} / \beta$. When looking at this as a contribution to the trace distance, we see that $e^{-\beta \Delta_S} g(\Delta_S - \gamma) \to e^{-\beta (\Delta_S - \epsilon \Delta_{\min}/2)} / \beta$, and since $\Delta_{\min} \leq \Delta_S$ by definition we have a vanishing trace distance.

    One thing to note is that if $\gamma$ is too large then we fall into the ``near-zero" approximation regime due to the large value of $t$. We had set $t$ such that for $\Delta \geq \Delta_{\min}$, then $\sinc^2(\Delta t/2) \leq \epsilon_{\sinc}$. This means that we require $\Delta_S - \gamma \leq \Delta_{\min}$ to fall within the window for any reasonable contribution from the $\sinc$. This gives us a window of $\pm \Delta_{\min}$ around $\Delta_S$ that we should have Now we let $\epsilon$ be a constant factor, say $\epsilon = 1/2$. This seems sufficient for now. Plugging in for the upper bound on the trace distance yields:
    \begin{equation}
        \norm{\rho_S(\beta) - \Phi(\rho_S(\beta))}_1 \leq \frac{\alpha^2 t^2}{\partfun (\dim + 1)} \parens{ \frac{2 e^{-\beta \Delta_S}}{\beta \Delta_{\min}} (\cosh(\beta \Delta_{\min} / 4) - 1) + 3 \epsilon_{\sinc} }
    \end{equation}

    What if instead of integrating really close to $\Delta_S$, we actually integrate the function over some much larger interval? Would this work? 
    \begin{align}
        \int_{\Delta_{\min}}^{\Delta_{\max}} g(\Delta_S - \gamma) \prob{\gamma} d\gamma &= \int_{\Delta_{\min}}^{\Delta_{\max}} \sinc^2((\Delta_S - \gamma)t/2)  \frac{\abs{1 - e^{\beta (\Delta_S - \gamma)}}}{\Delta_{\max} - \Delta_{\min}} d\gamma \\
        &= \int_{\Delta_{\min}}^{\Delta_S} \sinc^2((\Delta_S - \gamma)t/2) \frac{e^{\beta (\Delta_S - \gamma)} - 1}{\Delta_{\max} - \Delta_{\min} } d\gamma + \int_{\Delta_S}^{\Delta_{\max}} \sinc^2((\Delta_S - \gamma)t/2) \frac{1 - e^{- \beta (\gamma - \Delta_S)}}{\Delta_{\max} - \Delta_{\min} } d\gamma
    \end{align}
 
\begin{align}
    \norm{A}_1 &= \trace{\sqrt{A A^\dagger}} \\
    &= \trace{\sqrt{\sum_i |a_i|^2 \ketbra{i}{i}}} \\
    &= \trace{\sum_i |a_i| \ketbra{i}{i}} \\
    &= \sum_i |a_i|.
\end{align}

\subsection{Distance Reduction}
We now would like to show that some distance metric between an input state $\rho_S(\beta)$ and the desired output state $\rho_S(\beta_E)$ is decreasing upon application of $\Phi$. The most straightforward metric to use is the $\norm{\cdot}_2^2$ distance. Again, we restrict ourselves to the single qubit system as defined at the beginning of the section.

\begin{align}
    \norm{\rho_s(\beta_E) - \Phi(\rho_S(\beta))}_2^2 &= \norm{\rho_S(\beta_E) - \rho_S(\beta) - \sum_{i,j,k,l} \frac{e^{-\beta_E \lambda_E(j)}}{\partfun_E(\beta_E)} \frac{e^{-\beta \lambda_S(i)}}{\partfun_S(\beta)} \tau(i,j|k,l) \ketbra{k}{k} + R_3(\Phi)} _2^2
\end{align}
To simplify notation, we note that $\norm{R_3(\Phi)}_2^2 \leq \norm{R_3(\Phi)}_1^2 \in \bigo{\alpha^6}$ and introduce $A = \rho_S(\beta_E) - \rho_S(\beta)$ and $B = \sum_{i,j,k,l} \frac{e^{-\beta_E \lambda_E(j)}}{\partfun_E(\beta_E)} \frac{e^{-\beta \lambda_S(i)}}{\partfun_S(\beta)} \tau(i,j|k,l) \ketbra{k}{k}$. By dropping terms of order $\bigo{\alpha^6}$ for now we can compute
\begin{align}
    \norm{\rho_s(\beta_E) - \Phi(\rho_S(\beta))}_2^2 &\approx \norm{A - B}_2^2 \\
    &= \trace{(A-B)^\dagger (A - B)} \\
    &= \trace{A^2} - 2 \trace{A B} + \trace{B^2} \\
    &= \norm{A}_2^2 + \norm{B}_2^2 - 2 \trace{A B}.
\end{align}
Now in order to show that $\norm{\rho_s(\beta_E) - \Phi(\rho_S(\beta))}_2^2 \leq \norm{\rho_S(\beta_E) - \rho_S(\beta)}_2^2$, we need to show that $2 \trace{AB} \geq \trace{B^2}$.

First we note that since $A$ and $B$ are diagonal, we have $\trace{AB} = \sum_{k} A(k) B(k) = A(0)B(0) + A(1) B(1)$. We first compute the $k=0$ term and then $k=1$. For brevity, allow the following variables:
\begin{equation}
    a(i) = \frac{e^{-\beta \lambda_S(i)}}{\partfun_S(\beta)}, \quad b(j) = \frac{e^{-\beta_E \lambda_E(j)}}{\partfun_E(\beta_E)}.
\end{equation}

We first compute $B$, starting with $k=0$. We note that $\tau(i,j| k,l) = \tau(k,l |i,j)$ and that $\tau(i,j|i,j) = -\sum_{(a,b) \neq (i,j)} \tau(i,j| a,b)$.
\begin{align}
    B(0) &= \sum_{i,j,l} a(i) b(j) \tau(i,j|0,l) \\
    &= a(0) b(0) (\tau(0,0|0,0) + \tau(0,0|0,1)) + a(0)b(1) (\tau(0,1| 0,0) + \tau(0,1| 0,1)) \nonumber \\
    &\quad + a(1) b(0) (\tau(1,0|0,0) + \tau(1,0|0,1)) + a(1) b(1) (\tau(1,1|0,0) + \tau(1,1|0,1)) \\
    &= a(0) b(0) (-\tau(0,0|1,0) - \tau(0,0|1,1)) + a(0)b(1) (- \tau(0,1|1,0) -\tau(0,1|1,1)) \nonumber \\
    &\quad + a(1) b(0) (\tau(1,0|0,0) + \tau(1,0|0,1)) + a(1) b(1) (\tau(1,1|0,0) + \tau(1,1|0,1)) \\
    &= \tau(0,0|1,0) (-b(0) a(0) + b(0) a(1)) + \tau(0,0|1,1)(-b(0) a(0) + b(1) a(1)) \nonumber \\
    &\quad + \tau(0,1|1,0) (-b(1) a(0) + b(0) a(1)) + \tau(0,1|1,1)(-b(1) a(0) + b(1) a(1))
\end{align}
Next we compute $B(1)$ as
\begin{align}
    B(1) &= \sum_{i,j,l} \tau(i,j|1,l) \\
    &= a(0) b(0) (\tau(0,0|1,0) + \tau(0,0|1,1)) + a(0)b(1) (\tau(0,1| 1,0) + \tau(0,1| 1,1)) \nonumber \\
    &\quad + a(1) b(0) (\tau(1,0|1,0) + \tau(1,0|1,1)) + a(1) b(1) (\tau(1,1|1,0) + \tau(1,1|1,1)) \\
    &= a(0) b(0) (\tau(0,0|1,0) + \tau(0,0|1,1)) + a(0)b(1) (\tau(0,1| 1,0) + \tau(0,1| 1,1)) \nonumber \\
    &\quad + a(1) b(0) (- \tau(1,0|0,1) - \tau(1,0|0,0)) + a(1) b(1) (-\tau(1,1|0,0) - \tau(1,1|0,1)) \\
    &= \tau(0,0|1,0) (b(0) a(0) - b(0) a(1)) + \tau(0,0|1,1)(b(0) a(0) - b(1) a(1)) \nonumber \\
    &\quad + \tau(0,1|1,0) (b(1) a(0) - b(0) a(1)) + \tau(0,1|1,1)(b(1) a(0) - b(1) a(1)) \\
    &= - B(0).
\end{align}
This then leads to the equality $\trace{AB} = A(0) B(0) + A(1)B(1) = B(0) (A(0) - A(1))$. We investigate when each of these can be negative. 

\begin{align}
    A(0) - A(1) &= \frac{e^{-\beta_E \lambda_S(0)}}{\partfun_S(\beta_E)} - \frac{e^{-\beta \lambda_S(0)}}{\partfun_S(\beta)} - \frac{e^{-\beta_E \lambda_S(1)}}{\partfun_S(\beta_E)} + \frac{e^{-\beta \lambda_S(1)}}{\partfun_S(\beta)} \\
    &= \frac{e^{-\beta_E \lambda_S(0)} - e^{-\beta_E \lambda_S(1)}}{e^{-\beta_E \lambda_S(0)} + e^{-\beta_E \lambda_S(1)}} - \frac{e^{-\beta \lambda_S(0)} - e^{-\beta \lambda_S(1)}}{e^{-\beta \lambda_S(0)} + e^{-\beta \lambda_S(1)}} \\
    &= \frac{e^{\beta_E \Delta_S} - 1}{e^{\beta_E \Delta_S} + 1} - \frac{e^{\beta \Delta_S} - 1}{e^{\beta \Delta_S} + 1} \\
    &= \tanh(\beta_E \Delta_S / 2) - \tanh(\beta \Delta_S / 2).
\end{align}
Since $\tanh$ is a monotonic function, $\beta_E \geq \beta$ implies $A(0) - A(1) \geq 0$. For ease of notation, we define $T(\delta) \coloneqq \tanh(\beta_E \Delta_S /2) - \tanh((\beta_E -\delta)\Delta_S/2)$, where $\beta = \beta_E - \delta$.

 In order to determine what kind of bound should be used, we first simplify the overall expression:
\begin{align}
    \trace{A^2} - 2 \trace{AB} + \trace{B^2} &= \trace{A^2} - 2 (A(0) B(0) + A(1)B(1)) + B(0)^2 + B(1)^2 \\
    &= \trace{A^2} - 2 B(0)(A(0) - A(1)) + 2 B(0)^2 \\
    &= \trace{A^2} + 2 B(0)(B(0) - A(0) + A(1)) \label{eq:dist_decrease_a_and_b}
\end{align}
As our goal is to show $\norm{A - B}_2^2 \leq \norm{A}_2^2 - \epsilon$, we want to show $2 B(0) (B(0) -A(0) + A(1)) \leq - \epsilon$.

Now we work on bounding $B(0)$. We note that most of the non-energy preserving transitions (i.e all other than $\tau(0,1|1,0)$) can be bounded by a trivial bound of 0. Working term by term, along with the facts: $a(i) \geq 0$, $b(i) \geq 0$, and $i \leq j \implies a(i) \geq a(j) \& b(i) \geq b(j)$, $\tau(i,j|k,l) \geq 0$ if $(i,j) \neq (k,l)$ we get the following
\begin{align}
    \tau(0,0|1,0) b(0)(a(1) - a(0)) &\leq 0 \\
    \tau(0,0|1,1) (-b(0) a(0) + b(1) a(1)) &\leq \tau(0,0|1,1) b(0) (-a(0) + a(1)) \leq 0 \\
    \tau(0,1|1,1) b(1) (-a(0) + a(1)) &\leq 0.
\end{align}
This produces the bound $B(0) \leq \tau(0,1|1,0) (a(1)b(0) - a(0)b(1))$. Our goal is to further reduce this upper bound:
\begin{align}
    B(0) &\leq \tau(0,1|1,) \frac{1}{\partfun_E(\beta_E) \partfun_S(\beta)}\parens{e^{-\beta \lambda_S(1)} e^{-\beta_E \lambda_E(0)} - e^{-\beta \lambda_S(0)} e^{-\beta_E \lambda_E(1)}} \\
    &= \tau(0,1|1,0) \frac{e^{-\beta \lambda_S(1)}}{\partfun_E(\beta_E) \partfun_S(\beta)} (1 - e^{\beta \Delta_S - \beta_E \gamma })
\end{align}
Now we see that if $\beta \Delta_S \geq \beta_E \gamma$ then our bound becomes negative. If we let $\beta = \beta_E - \delta$ we have $\beta \Delta_S - \beta_E \gamma = \beta_E o$.
However, we could simply use the dumb bound:
\begin{align}
    B(0) &\leq \tau(0,1|1,0) (a(1) b(0) - a(0) b(1)) \\
    &\leq \tau(0,1|1,0) a(1) b(0) \\
    &\leq \frac{\alpha^2 t^2}{\dim + 1} \sinc^2((\Delta_S -\gamma)t/2)
\end{align}
We will use this for now.


The next tast is to construct a lower bound for $B(0)$. For this we repeat a similar term-by-term process as above. For a lower bound, however, we can take advantage that the non-degenerate transitions are upper bounded by $\epsilon_{\sinc}$. We also have $a(i),b(j) \leq 1$ as they are Boltzmann factors.
\begin{align}
    \tau(0,0|1,0) b(0) (a(1) - a(0)) \geq - \tau(0,0|1,0) a(0) b(0) \geq - \epsilon_{\sinc} \\
    \tau(0,0|1,1)(-b(0) a(0) + b(1)a(1)) \geq - \tau(0,0|1,1) a(0) b(0) \geq -\epsilon_{\sinc} \\
    \tau(0,1|1,1) b(1)(-a(0) + a(1) \geq - \tau(0,1|1,1) a(0)b(1) \geq - \epsilon_{\sinc}
\end{align}
The one remaining term is
\begin{align}
    \tau(0,1|1,0) (a(1)b(0) - a(0)b(1)) &= \frac{\alpha^2 t^2 \sinc^2((\Delta_S - \gamma) t/2)}{\dim + 1} \frac{1}{\partfun_E(\beta_E) \partfun_S(\beta)}(e^{-\beta \lambda_S(1) - \beta_E \lambda_E(0)} - e^{-\beta \lambda_S(0) - \beta_E \lambda_E(1)}) \\
    &= \frac{\alpha^2 t^2 \sinc^2((\Delta_S - \gamma) t/2)}{\dim + 1} \frac{e^{-\beta \lambda_S(1)}}{\partfun_E(\beta_E) \partfun_S(\beta)} (1 - e^{\beta \Delta_S - \beta_E \gamma})
\end{align}
Now we let $\beta = \beta_E - \delta$ and $\gamma = \Delta_S + \widetilde{\gamma}$. We get
\begin{align}
    1 - e^{(\beta_E - \delta)\Delta_S - \beta_E (\Delta_S + \widetilde{\gamma})} &= 1 - e^{-\delta \Delta_S - \beta_E \Delta_S - \beta_E \widetilde{\gamma}} \\
    &= 1 - e^{-\beta_E \Delta_S (1 - \delta / \beta_E + \widetilde{\gamma} / \Delta_S)}
\end{align}
We see that this is positive so long as $\widetilde{\gamma} \geq -\Delta_S(1 - \frac{\delta}{\beta_E})$. This is a fairly significant range if $\Delta_S$ is much larger than $\Delta_{\min}$. 

However, we can get a much simpler bound if we simply ignore these prefactors. We could bound it by:
\begin{align}
    \tau(0,1|1,0)(a(1) b(0) - a(0) b(1)) &\geq - \tau(0,1|1,0) a(0) b(1) \\
    &\geq - \frac{\alpha^2 t^2}{\dim + 1} \sinc^2((\Delta_S - \gamma)t/2)
\end{align}
Which yields $B(0) \geq -\parens{3 \epsilon_{\sinc} + \frac{\alpha^2 t^2}{\dim + 1} \sinc^2((\Delta_S - \gamma)t/2)}$.

Now that we have upper and lower bounds, we return to the original task of bounding the distance decrease. Our first goal is to upper bound $2 B(0)^2$. The issue we have is that $B(0)$ could be negative, in which case $\text{LB} \leq B(0) ~\&~ B(0) \leq \text{UB} \implies B(0)^2 \leq \min \set{\text{LB}^2, \text{UB}^2}$. So given the bounds we have computed and noting that $\epsilon_{\sinc} \geq 0$, we have $B(0)^2 \leq \frac{\alpha^2 t^2}{\dim  + 1} \sinc^2((\Delta_S - \gamma)t/2)$. 
\begin{align}
    &2 B(0)^2 - 2 B(0) (A(0) - A(1)) \\
    &\leq \parens{\frac{2 \alpha^2 t^2}{\dim + 1} \sinc^2 ((\Delta_S -\gamma)t/2)}^2 - 2\parens{3 \epsilon_{\sinc} + \frac{\alpha^2 t^2}{\dim + 1} \sinc^2 ((\Delta_S -\gamma)t/2)} T(\delta) \\
    &= - \epsilon
\end{align}
As we expect the $\alpha^4$ term to be dominated by the $\alpha^2$ term, we have that 
$$\epsilon \leq 2 (3 \epsilon_{\sinc} + \frac{\alpha^2 t^2}{\dim + 1} \sinc^2((\Delta_S - \gamma)t/2) T(\delta) - \parens{\frac{2 \alpha^2 t^2}{\dim + 1} \sinc^2 ((\Delta_S -\gamma)t/2)}^2.$$
Now we see the importance of knowing $\Delta_S$ to high precision, if $\Delta_S - \gamma \geq \Delta_{\min}$, then we see that $\sinc^2((\Delta_S - \gamma)t/2) \leq \epsilon_{\sinc}$ and we have that $\epsilon \in \bigo{\epsilon_{\sinc}}$. Since $\epsilon_{\sinc}$ is a user-defined paramater that we would like to take as small as possible, this would severely limit the distance that we converge to. Further, note that as $\delta \to 0$ $T(\delta) \to 0$, and we have that $\epsilon$ becomes negative, implying that our bounds break down at some point. 

We can then say that $\norm{\rho_S(\beta_E) - \Phi(\rho_S(\beta))}_2^2 \leq \norm{\rho_S(\beta_E) - \rho_S(\beta)}_2^2 - \epsilon$. By setting $\epsilon = \epsilon' \norm{\rho_S(\beta_E) - \rho_S(\beta)}_2^2$, we have
\begin{equation}
    \norm{\rho_S(\beta_E) - \Phi(\rho_S(\beta))}_2 \leq \norm{\rho_S(\beta_E) - \rho_S(\beta)}_2 \sqrt{1 - \epsilon'}
\end{equation}
It follows from standard Sch\"atten norm inequalities that $\norm{X}_2 \leq \sqrt{\dim} \norm{X}_{\infty} \leq \sqrt{\dim} \norm{X}_1$, which we can use to say:
\begin{align}
    \norm{\rho_S(\beta_E) - \Phi(\rho_S(\beta))}_1 &\leq  \sqrt{\dim} \norm{\rho_S(\beta_E) - \Phi(\rho_S(\beta))}_2 \\
    &\leq \parens{\dim \sqrt{1 - \epsilon'}} \norm{\rho_S(\beta_E) - \rho_S(\beta)}_1
\end{align}

\section{Generalizations to Many Qubits}

\begin{claim}
We now let $H_S = \sum_{i = 0}^{2^n - 1} \lambda_S(i) \ketbra{i}{i}$ be a system Hamiltonian over $n$ qubits. We utilize the same environment: a Hamiltonian $H_E = \begin{bmatrix}0 & 0 \\ 0 & \gamma\end{bmatrix}$ and state $\rho_E(\beta_E) = e^{-\beta_E H_E} / \partfun_E(\beta_E)$, along with the same interaction $G$. 
\end{claim}
\begin{proof}
Our goal is to show that our channel has $\rho_S(\beta_E)$ as a fixed point and that it reduces the distance to the fixed point at different temperatures. We start from Eq. \ref{eq:trace_dist_p_norm} with the goal of showing that $\norm{\rho_S(\beta_E) - \Phi(\rho_S(\beta_E))}_2^2 \leq \epsilon$. This reduces to showing
$$\sum_k \abs{\sum_{i,j,l} \frac{e^{-\beta_E \lambda(i,j)}}{\partfun(\beta_E)} \tau(i,j | k,l)}^2 \leq \epsilon.$$ 

The tool we will use to bound this sum is the fact that our map preserves trace to second order, which gives us $\tau(i,j|i,j) = - \sum_{(k,l) \neq (i,j)} \tau(i,j|k,l)$. We look first at a fixed value of $k$ and further let $a(i) = \bra{i} \rho_S \ket{i}$ and $b(j) = \bra{j} \rho_E \ket{j}$, which will allow us to generalize to non-thermal input states. By definition of density matrices we have $0 \leq a(i) \leq 1$ for all $i$ and similarly $0 \leq b(j) \leq 1$ for all $j$. 
\begin{align}
    \sum_{i,j,l} a(i) b(j) \tau(i,j | k,l) &= \sum_{i \neq k} \sum_{j,l} \parens{a(i) b(j) \tau(i,j|k,l)} + \sum_{j,l} a(k) b(j) \tau(k,j | k,l) \label{eq:n_qubit_fixed_pt_intermediate_1}.
\end{align}
We expand the simpler sum on the right:
\begin{align}
    \sum_{j,l}a(k) b(j) \tau(k,j| k,l) &= a(k) b(0) (\tau(k,0|k,0) + \tau(k,0|k,1)) + a(k) b(1) (\tau(k,1|k,0) + \tau(k,1|k,1)) \\
    &= - a(k) b(0) \sum_{c \neq k}\sum_{l} \tau(k,0 | c, l) - a(k) b(1) \sum_{c \neq k} \sum_{l}\tau(k,1|c,l) \\
    &= - \sum_{c \neq k} \sum_{j,l} a(k) b(j) \tau(k,j |c,l).
\end{align}
Plugging this into Eq. \ref{eq:n_qubit_fixed_pt_intermediate_1} allows us to simplify as follows
\begin{align}
    \sum_{i,j,l} a(i) b(j) \tau(i,j|k,l) &= \sum_{i \neq k} \sum_{j,l} (a(i) b(j) \tau(i,j|k,l)) - \sum_{c \neq k} \sum_{j,l} a(k) b(j) \tau(k,j|c,l) \\
    &= \sum_{i \neq k} \sum_{j,l} (a(i) b(j) \tau(i,j|k,l)) - \sum_{i \neq k} \sum_{j,l} a(k) b(l) \tau(i,j|k,l) \\
    &= \sum_{i \neq k} \sum_{j,l} (a(i) b(j) - a(k) b(l)) \tau(i,j | k,l).
\end{align}

We now can bound our desired quantity as follows
\begin{align}
    &\norm{\rho_S(\beta_E) - \Phi(\rho_S(\beta_E))}_2^2 \leq \sum_{k} \abs{\sum_{i \neq k} \sum_{j,l} ((a(i) b(j) -a(k) b(l)) \tau(i,j|k,l)}^2 \\
    &\leq \sum_{j,l,k} \sum_{i \neq k} \tau(i,j|k,l)^2 (a(i) b(j) - a(k) b(l))^2 \\
    &\leq \sum_{j,l,k} \sum_{i \neq k} \tau(i,j|k,l)^2 \\
    &= \sum_{j,l,k} \sum_{i \neq k} \frac{\alpha^4 t^4}{(\dim + 1)^2} \sinc(\Delta(i,j|k,l) t/ 2)^4 \\
    &= \parens{\frac{\alpha^2 t^2}{\dim + 1}}^2 \sum_k \sum_{i \neq k} \parens{2 \sinc\parens{ \frac{\Delta_S(i,k) t}{2}}^2 + \sinc\parens{\frac{(\Delta_S(i,k) - \gamma)t}{2}}^2 + \sinc\parens{\frac{(\Delta_S(i,k) + \gamma)t}{2}}^2} \\
    &\leq \parens{\frac{\alpha^2 t^2}{\dim + 1}}^2 \sum_k \sum_{i \neq k} \parens{3 \epsilon_{\sinc}^2 + \sinc\parens{\frac{(\Delta_S(i,k) - \gamma)t}{2}}^2} \\
    &\leq \parens{\frac{\alpha^2 t^2}{\dim + 1}}^2 (3 \epsilon_{\sinc}^2 \dim_S (\dim_S - 1) + \sum_{k} \sum_{i \neq k} \sinc\parens{\frac{(\Delta_S(i,k) - \gamma)t}{2}}^2.
\end{align}
Now given a specific value of $\gamma$ we can define a ``near-degeneracy" set of indices $S_\gamma$ that contains all indices $i,k$ such that their energy difference is close enough to $\gamma$:
\begin{equation}
    S_\gamma \coloneqq \set{(i,k) : i,k \in \set{1, 2, \ldots, \dim_S}, i \neq k, |\Delta_S(i,k) - \gamma| \leq \Delta_{\min}}.
\end{equation}
The size of this set can vary drastically depending on the eigenvalues of the system Hamiltonian. For example, take the harmonic oscillator with energy difference of 1 and set $\gamma = 1$. Then $S_{\gamma}$ in this case would be of size $|S_{1}| = \dim_S - 1$. On the other hand, take $H_S$ to be the identity, then $S_\gamma$ for any nonzero $\gamma$ is empty. 

Now picking back up from where we left off:
\begin{align}
    &= \parens{\frac{\alpha^2 t^2}{\dim + 1}}^2 (3 \epsilon_{\sinc}^2 \dim_S (\dim_S - 1) + \sum_{(i,k) \in S_{\gamma}} \sinc\parens{\frac{(\Delta_S(i,k) - \gamma)t}{2}}^2 + \epsilon_{\sinc}^2 (\dim_S^2 - |S_{\gamma}|)) \\
    &\leq \parens{\frac{\alpha^2 t^2}{\dim + 1}}^2 \parens{\epsilon_{\sinc}^2 (4 \dim_S^2 - 3 \dim_S - |S_{\gamma}|) + |S_{\gamma}|} \\
    &\leq \parens{\frac{\alpha^2 t^2}{\dim + 1}}^{2} \parens{\epsilon_{\sinc}^2 (4 \dim_S^2 - 3 \dim_S) + \dim_S(\dim_S - 1)}
\end{align}
We then can require that
\begin{equation}
    \alpha t \leq \epsilon^{1/4} \frac{\sqrt{\dim + 1}}{\dim_S (\dim_S - 1) + \epsilon_{\sinc}^2 (4 \dim_S^2 - 3 \dim_S)}
\end{equation}
which is enough to guarantee that $\norm{\rho_S(\beta_E) - \Phi(\rho_S(\beta_E))}_2^2 \leq \epsilon$. 
\end{proof}


I'm pretty sure this proof could be easily adapted to the trace distance.

Now what about the proof of convergence?

\bibliographystyle{unsrt}
\bibliography{bib}

\appendix
\section{Proof of Lemma \ref{lem:the_double_duhamel}}
\end{document}
