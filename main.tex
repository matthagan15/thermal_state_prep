\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage{amsmath,amsthm, amssymb}
\usepackage[margin=1.5cm]{geometry}
\usepackage{mathtools}
\usepackage{dsfont}
\usepackage{xcolor}
\usepackage{algorithm,algpseudocode}
\usepackage{todonotes}
\usepackage{nicefrac}
\usepackage{mathrsfs}
\usepackage{tikz}

%%%%%%%%    THEOREM DEFINITIONS AND RESTATABLE
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}

\usepackage{todonotes}

\newcommand{\matt}[1]{\todo[color=red!50, prepend, caption={Matt}, tickmarkheight=0.25cm]{#1}}
\newcommand{\note}[1]{\emph{Note: #1}}
\newcommand{\conjecture}[1]{ \noindent\emph{\textbf{Conjecture:}} \emph{ #1 }}




%%%%%%%%    NOTATION DEFINITIONS FOR EASIER WRITING
\newcommand{\ket}[1]{|#1\rangle}
\newcommand{\bra}[1]{\langle #1|}
\newcommand{\braket}[2]{\langle #1|#2\rangle}
\newcommand{\ketbra}[2]{| #1\rangle\! \langle #2|}
\newcommand{\parens}[1]{\left( #1 \right)}
\newcommand{\brackets}[1]{\left[ #1 \right]}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\norm}[1]{\left| \left| #1 \right| \right|}
\newcommand{\diamondnorm}[1]{\left| \left| #1 \right| \right|_\diamond}
\newcommand{\anglebrackets}[1]{\left< #1 \right>}
\newcommand{\overlap}[2]{\anglebrackets{#1 , #2 }}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\openone}{\mathds{1}}
\newcommand{\expect}[1]{\mathbb{E}\brackets{#1}}
\newcommand{\prob}[1]{\text{Pr}\left[ #1 \right]}
\newcommand{\bigo}[1]{\mathcal{O}\left( #1 \right)}
\newcommand{\bigotilde}[1]{\widetilde{\mathcal{O}} \left( #1 \right)}
\newcommand{\ts}{\textsuperscript}

\DeclareMathOperator{\Tr}{Tr}
\newcommand{\trace}[1]{\Tr \brackets{ #1 }}
\newcommand{\partrace}[2]{\Tr_{#1} \brackets{ #2 }}
\newcommand{\complex}{\mathbb{C}}

%%%%% COMMONLY USED OBJECTS
\newcommand{\hilb}{\mathscr{H}}
\newcommand{\partfun}{\mathcal{Z}}
\newcommand{\gue}{\rm GUE}
\DeclareMathOperator{\hermMathOp}{Herm}
\newcommand{\herm}[1]{\hermMathOp\parens{#1}}


\title{Thermal State Prep}
\author{Nathan Wiebe, Matthew Hagan}
\date{May 2022}

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
The computational task of preparing states of the form $\frac{e^{-\beta H}}{\partfun}$ in a usable approximation on a quantum computer is both incredibly useful and difficult. The closely related problem of estimating the free energy, defined as $F = -(1/\beta) \log \partfun$, up to additive error is known to be QMA-Hard for 2-local Hamiltonians \cite{bravyi_complexity_2021}. Intuitively, finding the ground state of a $k$-local Hamiltonian is known to be QMA-Hard \cite{} and the thermal state $e^{-\beta H} \partfun^{-1}$ can have arbitrarily high overlap with the ground state as $\beta \to \infty$ or the temperature approaches 0, indicating the problem for all computationally accessible $H$ and $\beta$ seems to be an incredibly difficult problem. 

The difficulty of preparing thermal states is offset by their incredible utility. Whenever low energy states are needed, such as when training Boltzmann machines \cite{}, preparing ground states for quantum error correcting codes \cite{}, or starting states for chemistry simulations \cite{}, thermal states correspond to natural choices for starting states. Even more broadly, thermal states can be used as resource states for SemiDefinite Program (SDP) solvers via a Quantum Aurora-Kale algorithm given by Brandao et al. \cite{}. 

Want to include here the main methods for preparing thermal states that currently exist, mainly the Poulin and Wocjan paper and Quantum-Quantum Metropolis Hastings. Where should more niche/advanced methods go?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Preliminaries}
We denote the Hilbert space of the system as $\hilb_{sys}$ and the environment as $\hilb_{env}$. The algorithm we propose for preparing thermal states for a Hamiltonian $H_{sys} \in \herm{\hilb_{sys}}$ involves direct time simulation of the system coupled to an environment governed by $H_{env} \in \herm{\hilb_{env}}$. We denote the interaction $H_{int} \in \herm{\hilb_{sys} \otimes \hilb_{env}}$. At a broad level, the algorithm starts from some initial state (what is the distribution over inputs?) we denote as $\rho$, undergoes time evolution with $H = H_{sys} + H_{env} + H_{int}$ for some time $t$, after which we trace out the environment leaving
\begin{equation}
    \mathcal{P}(\rho) = \partrace{Env}{e^{i H t} \rho e^{-i H t}}.
\end{equation}
The goal of this paper is to provide subsets of possible systems, environments, and interactions that can lead to efficient thermalization. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Harmonic Oscillators}
The first system we want to study is the two coupled Harmonic oscillators at first to get the machinery working and then extend one of the systems to something more general. We consider two systems, $\hilb_1 \otimes \hilb_2$, with two "base" hamiltonians $H_1 \otimes \openone$ and $\openone \otimes H_2$, where $H_1, H_2$ are finite approximations to a harmonic oscillator. For notation, we write $H_1 = \sum_{i = 0}^{n-1} \lambda_i u_i u_i^*$ and $H_2 = \sum_{j = 0}^{m} \nu_j v_j v_j^*$. Then we let $H = H_1 \otimes \openone + \openone \otimes H_2$, which has eigenvalue decomposition $H = \sum_{i,j} (\lambda_i + \nu_j) (u_i \otimes v_j)(u_i \otimes v_j)^*$. For simplicity, we will also use the notation $\eta_{i,j} := \lambda_i + \nu_j$ and $\Pi_{i,j} := (u_i \otimes v_j) (u_i \otimes v_j)^*$. We then consider adding in a perturbation $\alpha G$, where $\alpha \in [0, \infty)$ is a real coupling constant and $G$ is sampled from the Gaussian Unitary Ensemble (GUE) $G \sim GUE$. We denote perturbed expressions with tildes, so our perturbed hamiltonian is $\widetilde{H} = H + \alpha G$ with eigenvalues $\widetilde{\eta}_{i,j}$ and eigenspace projectors $\widetilde{\Pi}_{i,j}$. 

The channel we would like to replicate is
\begin{equation}
    \Phi(\rho) = \partrace{\hilb_2}{\int dG e^{+i \widetilde{H} t} \rho e^{- i \widetilde{H} t}} = \partrace{\hilb_2}{\int dG \Phi_G(\rho)}.
\end{equation}
Our goal is to show that for some performance metric this channel takes thermal states defined for $H_1, H_2$ and outputs a thermal state on $\hilb_1$ with a lower temperature than it began with. In other words, if we let $d(\rho, \sigma)$ represent the metric of interest then we would like $d \parens{ \partfun_3^{-1} e^{-\beta_3 H_1}, \Phi\parens{\partfun_1^{-1} e^{-\beta_1 H_1} \otimes \partfun_2^{-1}e^{-\beta_2 H_2}} }$ to be small (if we think of it as a distance, high if it's some kind of overlap). There are a few various metrics we could look at: the trace distance, fidelity, difference in overlap on a single observable, or the difference in overlap averaged over a distribution over all possible observables. 

\begin{itemize}
    \item Fidelity: $F(P, Q) := \trace{\sqrt{\sqrt{P} Q \sqrt{P}}}$. The biggest issue I could see here is the square root, it seems like the thing in the square root might be fairly straightforward to compute. 
    \item Trace distance: $\norm{P - Q}_1 = \trace{\sqrt{(P-Q)^*(P-Q)}}$
    \item Overlap: $\anglebrackets{P, Q} = \trace{P^* Q}$, similar to dot product for vectors. This is not super useful, note if $P = Q$ then the overlap isn't even one and is more a measure of the purity of the state. 
    \item Measurement statistics for a single observable: Let $\mu(i)$ denote a measurement, could correspond to eigenspace projectors for some Hermitian observable. Then the vector defined by $\overlap{\mu(i)}{P}$ denotes the probability vector for the measurement $\mu$. We could take the Kullback-Leibler divergence of these vectors for $P, Q$.
    \item Measurement statistics for an ensemble of observables: The idea behind this is that the trace distance corresponds to an upper bound on the distinguishability between $P,Q$ as defined by their measurement statistics. If instead of looking at the maximum, what if we specify a distribution over possible observables and then look at the measurement statistic differences? 
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Simplifying $\Phi(\rho)$ with Perturbation Theory}
The goal is to use perturbation theory to write the output of the channel in terms of powers of the coupling strength $\alpha$. It remains to be seen if first order perturbation theory will be enough. We also are specifically interested when $\rho$ is a product state of thermal states, in other words $\rho_{PS} = \frac{e^{-\beta_1 H_1}}{\partfun_1} \otimes \frac{e^{-\beta_2 H_2}}{\partfun_2}$. We also denote the action of our channel with respect to a particular choice of $G$ as $\Phi_G$, which combined with linearity of partial traces gives $\Phi = \int dG \Phi_G$. 
\begin{align}
    \Phi_G(\rho_{PS}) &= \partrace{2}{e^{+i \widetilde{H} t} \rho_{PS} e^{-i \widetilde{H} t}} \\
    &= \sum_{k} \openone \otimes v_k^* \parens{\sum_{i, j} e^{i \widetilde{\eta}_{i, j} t} \widetilde{\Pi}_{i,j}} \rho_{PS} \parens{ \sum_{m, n} e^{i \widetilde{\eta}_{m, n} t} \widetilde{\Pi}_{m,n} }
\end{align}
Our next goal is to analyze $e^{i \widetilde{\eta}_{i,j} t} \widetilde{\Pi}_{i,j}$ using time-independent perturbation theory. Our goal is to write $e^{i \widetilde{\eta}_{i,j} t}$ as a power series in terms of $\alpha$, which is given by perturbation theory for $\widetilde{H} = H + \alpha G$. We first write the perturbation series for $\widetilde{\eta}$ as 
\begin{equation}
    \widetilde{\eta}_{i,j} = \eta_{i,j} + \alpha (u_i \otimes v_j)^* G (u_i \otimes v_j) + \alpha^2 \sum_{(i',j') \neq (i,j)}  \frac{\abs{(u_i \otimes v_j)^* G (u_{i'} \otimes v_{j'})}^{2}}{\eta_{i,j} - \eta_{i',j'}} + \bigo{\alpha^3}.
\end{equation}
To simplify the notation, we introduce the indexing $G(i,j,k,l) := (u_i \otimes v_j)^* G (u_k \otimes v_l)$. $G(i,j)$ without a second pair of indices denotes the diagonal matrix element $(u_i \otimes v_j)^* G (u_i \otimes v_j)$. The Taylor's Series for $e^{i \widetilde{\eta}_{i,j} t}$ is
\begin{align}
    e^{i \widetilde{\eta}_{i,j} t} &= e^{i \eta_{i,j} t} \\
    &\quad + \frac{\partial \widetilde{\eta}_{i,j}}{\partial \alpha} e^{i \widetilde{\eta}_{i,j}t} \bigg|_{\alpha = 0} i \alpha t \\
    &\quad + \frac{ i\alpha^2 t}{2!} \frac{\partial^2 \widetilde{\eta}_{i,j}}{\partial \alpha^2} e^{i \widetilde{\eta}_{i,j}t}\bigg|_{\alpha=0} \\
    &\quad - \frac{\alpha^2 t^2}{2!} \parens{\frac{\partial \widetilde{\eta}_{i,j}}{\partial \alpha}}^2 e^{i \widetilde{\eta}_{i,j} t} \bigg|_{\alpha=0} + \bigo{\alpha^3} .
\end{align}
These are rather straightforward to compute and plug in, yielding
\begin{equation}
    e^{i \widetilde{\eta}_{ij} t} = e^{i \eta_{ij} t}\parens{1 + i \alpha t G(i,j) - \frac{\alpha^2 t^2}{2} G(i,j)^2 + i \frac{\alpha^2 t}{2} \sum_{(i',j') \neq (i,j)}\frac{\abs{G(i',j',i,j)}^2}{\eta_{ij} - \eta_{i' j'}} + \bigo{\alpha^3}}.
\end{equation}
This is sloppy, need to be able to bound the $\bigo{\alpha^3}$ terms better. Also note that $G(i,j)$ is a real Gaussian variable, the realness is due to the Hermiticity constraint on $G$. 

The other quantity we need to compute a perturbation series for is $\widetilde{\Pi}_{ij}$. We first need to compute the perturbation series for the eigenvectors of $H$, which we do to second order
\begin{align}
    \widetilde{u_i \otimes v_j} &= u_i \otimes v_j \\
    &\quad + \alpha \sum_{(i',j') \neq (i,j)} u_{i'} \otimes v_{j'} \parens{  \frac{G(i,j,i',j')}{\eta_{i,j} - \eta_{i',j'}} } \\
    &\quad + \alpha^2 \sum_{(i',j') \neq (i,j)} u_{i'} \otimes v_{j'} \parens{ \sum_{(i'',j'') \neq (i,j)} \frac{G(i,j,i'',j'') G(i'',j'',i',j')}{(\eta_{i,j} - \eta_{i'',j''})(\eta_{i,j} - \eta_{i'',j''})} -  \frac{G(i,j,i,j) G(i,j,i',j')}{(\eta_{i,j} - \eta_{i',j'})^2}} \\
    &\quad + \bigo{\alpha^3}.
\end{align}
Now we need to compute the perturbed eigenspace projectors
\begin{align}
    \widetilde{\Pi}_{i,j} &= \Pi_{i,j} \\
    & \quad + \alpha \sum_{(i',j') \neq (i,j)} u_{i'} u_i^* \otimes v_{j'} v_j^* \parens{  \frac{G(i,j,i',j')}{\eta_{i,j} - \eta_{i',j'}} } + \sum_{(i',j') \neq (i,j)} u_i u_{i'}^* \otimes v_j v_{j'}^* \parens{  \frac{G(i,j,i',j')^*}{\eta_{i,j} - \eta_{i',j'}} } \\
    & \quad + \alpha^2 \sum_{(i',j') \neq (i,j)} u_{i'} u_i^* \otimes v_{j'} v_j^* \parens{ \sum_{(i'',j'') \neq (i,j)} \frac{G(i,j,i'',j'') G(i'',j'',i',j')}{(\eta_{i,j} - \eta_{i'',j''})(\eta_{i,j} - \eta_{i'',j''})} -  \frac{G(i,j,i,j) G(i,j,i',j')}{(\eta_{i,j} - \eta_{i',j'})^2}} \\
    & \quad + \alpha^2 \sum_{(i',j') \neq (i,j)} u_i u_{i'}^* \otimes v_j v_{j'}^* \parens{ \sum_{(i'',j'') \neq (i,j)} \frac{G(i,j,i'',j'')^* G(i'',j'',i',j')^*}{(\eta_{i,j} - \eta_{i'',j''})(\eta_{i,j} - \eta_{i'',j''})} -  \frac{G(i,j,i,j)^* G(i,j,i',j')^*}{(\eta_{i,j} - \eta_{i',j'})^2}} \\
    & \quad + \alpha^2 \sum_{(i',j') \neq (i,j)} \sum_{(i'',j'') \neq (i,j)} u_{i'}u_{i''}^* \otimes v_{j'} v_{j''}^* \frac{G(i,j,i',j') G(i,j,i'',j'')^*}{(\eta_{i,j} - \eta_{i',j'})(\eta_{i,j} - \eta_{i'',j''})} \\
    & \quad + \bigo{\alpha^3}.
\end{align}

This allows us to write the output of the channel $\Phi$ as a power series in $\alpha$. The expressions can become quite cumbersome, so we introduce the following notation:
\begin{align}
    M_{i,j,i',j'} &:=  u_{i'} u_i^* \otimes v_{j'} v_j^* \parens{  \frac{G(i,j,i',j')}{\eta_{i,j} - \eta_{i',j'}} } +  u_i u_{i'}^* \otimes v_j v_{j'}^* \parens{  \frac{G(i,j,i',j')^*}{\eta_{i,j} - \eta_{i',j'}} } \\
    N_{i,j,i',j'} &:= u_{i'} u_i^* \otimes v_{j'} v_j^* \parens{ \sum_{(i'',j'') \neq (i,j)} \frac{G(i,j,i'',j'') G(i'',j'',i',j')}{(\eta_{i,j} - \eta_{i'',j''})(\eta_{i,j} - \eta_{i'',j''})} -  \frac{G(i,j,i,j) G(i,j,i',j')}{(\eta_{i,j} - \eta_{i',j'})^2}} \\
    & \quad + \sum_{(i'',j'') \neq (i,j)} u_{i'}u_{i''}^* \otimes v_{j'} v_{j''}^* \frac{G(i,j,i',j') G(i,j,i'',j'')^*}{(\eta_{i,j} - \eta_{i',j'})(\eta_{i,j} - \eta_{i'',j''})}
\end{align}
which captures the first and second order corrections to the eigenspace projectors. We can then simplify
\begin{align}
    \widetilde{\Pi}_{i,j} &= \Pi_{i,j} + \alpha \sum_{(i',j') \neq (i,j)} M_{i,j,i',j'} + \alpha^2 \sum_{(i',j') \neq (i,j)} N_{i,j,i',j'} + \bigo{\alpha^3}
\end{align}
The second order corrections have 10 possible sources for terms, however many are hermitian conjugates of priors, so if herm. conj. appears it refers to the hermitian conjugate of the entire previous line.
\newpage
\begin{equation}
    e^{+i(H + \alpha G)t} \rho e^{-i (H + \alpha G) t}
\end{equation}
\begin{align}
\alpha^0 :& e^{+i H t} \rho e^{-i H t} \\
 \alpha^1 :& \sum_{i,j} e^{i\eta_{i,j}t} \parens{i t G(i,j) \Pi_{i,j} + \sum_{(i',j') \neq (i,j)} M_{i,j,i',j'}} \rho e^{- i H t} \\
 &+ \text{herm. conj.} \\
 \alpha^2 :& \sum_{i,j} i t G(i,j) e^{i \eta_{i,j}} \Pi_{i,j} \rho \sum_{k,l} (-i t) G(k,l)^* e^{-i \eta_{k,l}t} \Pi_{k,l} \\
 &+ \sum_{i,j} e^{i \eta_{i,j} t} \sum_{(i',j') \neq (i,j)} M_{i,j,i',j'} \rho \sum_{k,l} (-i t) G(k,l) e^{-i \eta_{k,l} t} \Pi_{k,l} \\
 &+ \text{herm. conj.} \\
 &+ \sum_{i,j} e^{i \eta_{i,j} t} \sum_{(i',j') \neq (i,j)} M_{i,j,i',j'} \rho \sum_{k,l} e^{-i \eta_{k,l} t} \sum_{(k',l') \neq (k,l)} M_{k,l,k',l'}\\
 &+  \sum_{i,j} e^{i \eta_{i,j} t} \parens{- \frac{t^2 G(i,j)^2}{2} + i \frac{t}{2} \sum_{(i',j') \neq (i,j)} \frac{\abs{G(i,j,i',j')}^2}{\eta_{i,j} - \eta_{i',j'}} } \rho e^{- i H t} \\
 &+ \text{herm. conj.} \\
 &+ \sum_{i,j} e^{i \eta_{i,j} t} \sum_{(i',j') \neq (i,j)} N_{i,j,i',j'} \rho e^{-i H t} \\
 &+ \text{herm. conj.} \\
 &+ \sum_{i,j} i t G(i,j) e^{i \eta_{i,j} t} \sum_{(i',j') \neq (i,j)} M_{i,j,i',j'} \rho e^{-i H t} \\
 &+ \text{herm. conj.}.
\end{align}

Two potential issues. 1) How can we normalize the output state? This may depend on how we approach the second. 2) How do we bound the remaining terms in the perturbation series? Are there any dumb bounds I can work out? 

Now that we have expressions for the output channel in terms of a perturbative expansion, we can continue with finding the output after tracing out the environment and considering the GUE averaging integral. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Simplifying $\Phi(\rho)$ with Trotter}
The idea here is to try and see what very short time evolution does to our channel. At the very least this might give some intuition as to what is happening?
\begin{align}
    \Phi_G(\rho_{PS}) &= \partrace{2}{e^{+i\widetilde{H}t} \rho_{PS} e^{-i \widetilde{H} t}} \\
    &= \partrace{2}{\parens{e^{i G \alpha t} e^{i H t} + \bigo{t^2}} \rho_{PS} \parens{e^{-iHt} e^{-i G \alpha t} + \bigo{t^2}}} \\
    &= \partrace{2}{e^{i G \alpha t} \rho_{PS} e^{-i G \alpha t}} + \bigo{t^2} 
\end{align}


\subsection{Computing $\Phi_G$ with Duhamel's formula}
We would like to produce a Taylor Series of the expression $\Phi_G = e^{i(H+\alpha G) t} \rho e^{-i(H+\alpha G) t}$ with respect to the coupling constant $\alpha$. To do this we use Duhamel's formula for differentiation of the exponent of a matrix exponential
\begin{equation}
    \frac{d}{dt} e^{A(t)} = \int_0^1 e^{s A(t)} \frac{d A(t)}{dt} e^{(1-s)A(t)} ds.
\end{equation}
Our goal is to write $\Phi_G = \rho(t) + \alpha \frac{\partial}{\partial \alpha} \Phi_G \big|_{\alpha=0} + \frac{\alpha^2}{2!} \frac{\partial^2}{\partial \alpha^2} \Phi_G \big|_{\alpha=0} + R$. The first term can be computed as
\begin{align}
    \frac{\partial}{\partial \alpha} e^{i(H+\alpha G)t} \rho e^{-i (H+\alpha G)t} \bigg|_{\alpha = 0} &= \int_{0}^{1} e^{i s (H+\alpha G)t} (i t G) e^{i (1-s) (H+\alpha G)t} ds \rho e^{-i(H+\alpha G)t} \bigg|_{\alpha=0} \nonumber \\
    &\text{ } + e^{i(H+\alpha G)t} \rho \int_{0}^1 e^{-i s (H+\alpha G) t} (- i t G) e^{-i (1-s) (H+\alpha G)t} ds \bigg|_{\alpha = 0} \label{eq:first_order_alpha_derivative}\\
    &= i t \int_0^1 e^{i s H t} G e^{-i s H t} ds e^{i H t} \rho e^{-i H t} - i t e^{+i H t} \rho \int_0^1 e^{-is H t} G e^{-i(1-s) Ht} ds \\
    &= i t \int_0^1 G(s t) ds \rho(t) - it \rho(t) \int_0^1 G(s t) ds \\
    &= i t \int_0^1 [G(s t), \rho(t)] ds.
\end{align}

Now we can compute the second order term by differentiating Eq. \eqref{eq:first_order_alpha_derivative} inside of the $\big|_{\alpha = 0}$. Note that there are 3 locations for the derivative to act in each term, yielding 6 final terms. To give a sense of how each term is computed we will compute the first one explicitly and simply state the remaining terms.
\begin{align}
    &i t\int_0^1 \parens{\frac{\partial}{\partial \alpha} e^{i s_1 (H+ \alpha G)t}} G e^{i(1-s_1)(H+\alpha G)t} ds_1 \rho e^{-i (H+\alpha G)t} \bigg|_{\alpha=0} \\
    &= (it)^2 \int_0^1 \int_0^1 e^{i s_1 s_2 (H+\alpha G)t} s_1 G e^{i s_1 (1-s_2) (H+\alpha G)t} ds_2 G e^{i(1-s_1) (H+\alpha G)t} ds_1 \rho e^{-i(H+\alpha G) t} \bigg|_{\alpha=0} \\
    &= -t^2 \int_0^1 \int_0^1 e^{i s_1 s_2 H t} G e^{-i s_1 s_2 H t} e^{i s_1 H t} G e^{-i s_1 H t} s_1 ds_1 ds_2 e^{i H t} \rho e^{-i H t} \\
    &= -t^2 \int_0^1 \int_0^1 G(s_1 s_2 t) G(s_1 t) s_1 ds_1 ds_2 \rho(t).
\end{align}
The remaining terms we compute using a similar process, and are stated as
\begin{align}
    & -t^2 \int_0^1 \int_0^1 G(s_1 t) G((s_1 + s_2 - s_1 s_2) t) (1-s_1) ds_z1 ds_2 \rho (t) \\
    & +t^2 \int_0^1 G(st) ds \rho(t) \int_0^1 G(st) ds \\
    & +t^2 \int_0^1 G(st) ds \rho(t) \int_0^1 G(st) ds \\
    & -t^2 \rho(t) \int_0^1 \int_0^1 G((1-s_1)t) G((1-s_1 s_2) t) s_1 ds_1 ds_2 \\
    & -t^2 \rho(t) \int_0^1 \int_0^1 G((1-s_1)t) G((1-s_1)(1 - s_2) t) (1-s_1) ds_1 ds_2.
\end{align}
For the last two terms we can make them look similar to the first two by redefining the integration variables. This leads to the simplified expression
\begin{align}
    \frac{\partial^2}{\partial \alpha^2} \Phi_G \bigg|_{\alpha = 0} &= 2 t^2 \int_0^1 G(st) ds \rho(t) \int_0^1 G(st) ds \\
    &\text{ } - t^2 \int_0^1 \int_0^1 \brackets{\rho(t) , G(s_1 t) G(s_1 s_2 t)}_+ s_1 ds_1 ds_2 \\
    &\text{ } - t^2 \int_0^1 \int_0^1 \brackets{ \rho(t), G(s_1 t) G((s_1 + s_2 - s_1 s_2) t) }_+ (1-s_1) ds_1 ds_2 \\
\end{align}



\section{Energy and Entropic concerns}
One requirement that our construction should satisfy is that a system in a thermal state should be invariant under contact with an environment at the same temperature. Formally, we would like that $\Phi \parens{\frac{e^{-\beta H_{sys}}}{\partfun_{sys}} \otimes \frac{e^{- \beta H_{env}}}{\partfun_{env}}} = \frac{e^{-\beta H_{sys}}}{\partfun_{sys}}$. Exact equality may be too strong to enforce, so we instead consider that the energy of the system remains unchanged after coupling with the environment. 

\begin{equation}
    \trace{H_{sys} \frac{e^{-\beta H_{sys}}}{\partfun_{sys}}} = \trace{H_{sys} \Phi \parens{\frac{e^{-\beta H_{sys}}}{\partfun_{sys}} \otimes \frac{e^{- \beta H_{env}}}{\partfun_{env}}}}.
\end{equation}
Now we look at the RHS in detail
\begin{align}
    \trace{H_{sys} \Phi \parens{\rho} } &= \trace{ H_{sys} \partrace{env}{\int e^{i \widetilde{H} t} \rho e^{-i \widetilde{H} t} dG}} \\
    &= \int \trace{H_{sys} \otimes \openone_{env} e^{i \widetilde{H} t} \rho e^{-i \widetilde{H} t} } dG \\
    &=  \trace{\int e^{- i (H + \alpha G) t} H_{sys} \otimes \openone_{env} e^{+ i (H + \alpha G) t} dG ~ \rho }
\end{align}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Approximating $e^{i (H + \alpha G) t}$ evolution}

\bibliographystyle{unsrt}
\bibliography{bib}

\end{document}
