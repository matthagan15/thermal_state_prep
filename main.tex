\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage{amsmath,amsthm, amssymb}
\usepackage[margin=1.5cm]{geometry}
\usepackage{mathtools}
\usepackage{dsfont}
\usepackage{xcolor}
\usepackage{algorithm,algpseudocode}
\usepackage{todonotes}
\usepackage{nicefrac}
\usepackage{mathrsfs}
\usepackage{tikz}
\usepackage{thm-restate}


%%%%%%%%    THEOREM DEFINITIONS AND RESTATABLE
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}

\usepackage{todonotes}

\newcommand{\matt}[1]{\todo[color=red!50, prepend, caption={Matt}, tickmarkheight=0.25cm]{#1}}
\newcommand{\note}[1]{\emph{Note: #1}}
\newcommand{\conjecture}[1]{ \noindent\emph{\textbf{Conjecture:}} \emph{ #1 }}




%%%%%%%%    NOTATION DEFINITIONS FOR EASIER WRITING
\newcommand{\ket}[1]{|#1\rangle}
\newcommand{\bra}[1]{\langle #1|}
\newcommand{\braket}[2]{\langle #1|#2\rangle}
\newcommand{\ketbra}[2]{| #1\rangle\! \langle #2|}
\newcommand{\parens}[1]{\left( #1 \right)}
\newcommand{\brackets}[1]{\left[ #1 \right]}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\norm}[1]{\left| \left| #1 \right| \right|}
\newcommand{\diamondnorm}[1]{\left| \left| #1 \right| \right|_\diamond}
\newcommand{\anglebrackets}[1]{\left< #1 \right>}
\newcommand{\overlap}[2]{\anglebrackets{#1 , #2 }}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\openone}{\mathds{1}}
\newcommand{\expect}[1]{\mathbb{E}\brackets{#1}}
\newcommand{\prob}[1]{\text{Pr}\left[ #1 \right]}
\newcommand{\bigo}[1]{\mathcal{O}\left( #1 \right)}
\newcommand{\bigotilde}[1]{\widetilde{\mathcal{O}} \left( #1 \right)}
\newcommand{\ts}{\textsuperscript}

\DeclareMathOperator{\Tr}{Tr}
\newcommand{\trace}[1]{\Tr \brackets{ #1 }}
\newcommand{\partrace}[2]{\Tr_{#1} \brackets{ #2 }}
\newcommand{\complex}{\mathbb{C}}

%%%%% COMMONLY USED OBJECTS
\newcommand{\hilb}{\mathcal{H}}
\newcommand{\partfun}{\mathcal{Z}}
\newcommand{\identity}{\mathds{1}}
\newcommand{\gue}{\rm GUE}
\DeclareMathOperator{\hermMathOp}{Herm}
\newcommand{\herm}[1]{\hermMathOp\parens{#1}}


\title{Thermal State Prep}
\author{Nathan Wiebe, Matthew Hagan}
\date{May 2022}

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
Going to leave this blank for now. 

Want to include here the main methods for preparing thermal states that currently exist, mainly the Poulin and Wocjan paper and Quantum-Quantum Metropolis Hastings. Where should more niche/advanced methods go? \cite{shiraishi_undecidability_2021}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Preliminaries}
We denote the Hilbert space of the system as $\hilb_{sys}$ and the environment as $\hilb_{env}$, with the Hamiltonians governing each as $H_{sys}$ and $H_{env}$. The Hamiltonian for the joint system on $\hilb_{sys} \otimes \hilb_{env}$ is then $H = H_{sys} \otimes \identity + \identity \otimes H_{env}$. We study the effects of simulating the time dynamics of the system-environment space with randomized interactions. Our goal is to produce a channel that can reduce the entropy of a system thermal state by utilizing easily prepared thermal states of the environment. We consider using the Haar measure over eigenvectors for the randomized interaction and i.i.d eigenvalues from a zero mean $\sigma^2$ variance distribution. We consider input states of the form $\rho(\beta_S, \beta_E) = \frac{e^{-\beta_S H_{sys}}}{\partfun_{sys}} \otimes \frac{e^{-\beta_E H_{env}}}{\partfun_{env}}$ and will simply use $\rho$ until the thermal nature of our inputs are necessary. The thermal states for the environment are supposed to be easily preparable.

The Hamiltonians $H_{sys}$ and $H_{env}$ form a basis for the tensor product space. As we are not concerned with specific details of the eigenvectors of each, we will refer to them by an arbitrary index. Let $E_{i,j}$ denote the eigenvalue $E_i(H_{sys}) + E_j(H_{env})$ and $\ket{i,j}$ the corresponding eigenvector. Without loss of generality we will focus on spaces in which the system can be represented with $n$ qubits and the environment with $m$ qubits. So we have
\begin{equation}
    H_{sys} = \sum_{i = 0}^{2^n - 1} E_i \ketbra{i}{i} ~,~ H_{env} = \sum_{j=0}^{2^m - 1} E_j \ketbra{j}{j} ~,~ H = \sum_{i=0}^{2^n - 1} \sum_{j=0}^{2^m - 1} E_{i,j} \ketbra{i,j}{i,j}.
\end{equation}
The above is just to put all the chosen notation in a convenient place. 


Overall one application of our channel is represented as
\begin{equation}
    \Phi(\rho) := \int \partrace{env}{e^{+i(H + \alpha G)t} \rho e^{-i(H + \alpha G) t}} dG.
\end{equation}
For simplicity we will denote the time evolution channel for a specific random interaction $G$ as
\begin{equation}
    \Phi_G(\rho) := e^{+i (H+ \alpha G) t} \rho e^{-i (H + \alpha G) t}.
\end{equation}
Clearly then $\Phi = \int \partrace{env}{\Phi_G} dG$. We use $G$ to denote the randomized interaction term, where $G = U_G D U_G^\dagger$. The measure we choose for the eigenbasis of $G$ is $U_G \sim Haar$ and the eigenvalues are i.i.d with mean 0 and variance $\sigma^2$. This gives the overall measure decomposition $dG = dD ~ dU_G$. 

\begin{restatable}{lemma}{haar_two_moment} \label{lem:haar_two_moment}
    Let $U$ be a unitary matrix over $d$ dimensions that is distributed according to the Haar measure. The $k=2$ polynomial can be integrated as
    \begin{align}
        \int \bra{i_1} U \ket{j_1} \bra{i_2} U \ket{j_2} \overline{\bra{k_1} U \ket{l_1}} ~ \overline{\bra{k_2} U \ket{l_2}} dU =& ~\frac{1}{d^2 - 1} \parens{\delta_{i_1, k_1} \delta_{j_1, l_1} \delta_{i_2, k_2} \delta_{j_2, l_2} + \delta_{i_1, k_2} \delta_{j_1, l_2} \delta_{i_2, k_1} \delta_{j_2, l_1}} \nonumber \\
        &- \frac{1}{d(d^2 - 1)} \parens{\delta_{i_1, k_2} \delta_{j_1, l_1} \delta_{i_2, k_1} \delta_{j_2, l_2} + \delta_{i_1, k_1} \delta_{j_1, l_2} \delta_{i_2, k_2} \delta_{j_2, l_1}}. \label{eq:haar_two_moment_integral}
    \end{align}
    \end{restatable}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Fixed Points}
Our first goal is to show that $\rho(\beta, \beta)$ is a fixed point, at least approximately, of the channel $\Phi$. We then aim to show that it is an attractor for states of the form $\rho(\beta_S, \beta_E)$ with $\beta_E > \beta_S$. 

\subsection{Computing $\Phi_G$ with Duhamel's formula}
Our first goal is to compute the Taylor's series for $\Phi$ with respect to the coupling constant $\alpha$. To do this we compute the Taylor Series for $\Phi_G$ and then compute the effects of integrating and partial traces. We make use Duhamel's formula for differentiation of the exponent of a matrix exponential
\begin{equation}
    \frac{d}{dt} e^{A(t)} = \int_0^1 e^{s A(t)} \frac{d A(t)}{dt} e^{(1-s)A(t)} ds.
\end{equation}
The object of interest is $$\Phi_G = \rho(t) + \alpha \frac{\partial}{\partial \alpha} \Phi_G \big|_{\alpha=0} + \frac{\alpha^2}{2!} \frac{\partial^2}{\partial \alpha^2} \Phi_G \big|_{\alpha=0} + R.$$ Then due to linearity of integration and partial traces this will give us a series expansion in $\alpha$ for the overall channel $\Phi$. We first focus on computing the first two non-trivial terms and focus on bounding the magnitude of $R$ later. 
The first order term can be computed as
\begin{align}
    \frac{\partial}{\partial \alpha} e^{i(H+\alpha G)t} \rho e^{-i (H+\alpha G)t} \bigg|_{\alpha = 0} &= \int_{0}^{1} e^{i s (H+\alpha G)t} (i t G) e^{i (1-s) (H+\alpha G)t} ds \rho e^{-i(H+\alpha G)t} \bigg|_{\alpha=0} \nonumber \\
    &\text{ } + e^{i(H+\alpha G)t} \rho \int_{0}^1 e^{-i s (H+\alpha G) t} (- i t G) e^{-i (1-s) (H+\alpha G)t} ds \bigg|_{\alpha = 0} \label{eq:first_order_alpha_derivative}\\
    &= i t \int_0^1 e^{i s H t} G e^{-i s H t} ds e^{i H t} \rho e^{-i H t} - i t e^{+i H t} \rho \int_0^1 e^{-is H t} G e^{-i(1-s) Ht} ds \\
    &= i t \int_0^1 G(s t) ds \rho(t) - it \rho(t) \int_0^1 G(s t) ds \\
    &= i t \int_0^1 [G(s t), \rho(t)] ds.
\end{align}

This term is negligible in the overall channel due to the eigenvalues having mean 0. This is computed as
\begin{align}
    \frac{\partial}{\partial \alpha} \Phi(\rho) \bigg|_{\alpha = 0} &= \frac{\partial}{\partial \alpha} \partrace{env}{\int \Phi_G(\rho) ~dG} \bigg|_{\alpha=0} \\
    &= \partrace{env}{\int\frac{\partial \Phi_G(\rho)}{\partial \alpha} \bigg|_{\alpha=0} dG } \\
    &= i t \partrace{env}{\int_0^1 \int [e^{i H s t} G e^{-i H s t}, \rho(t)] dG ds} \\
    &= i t \partrace{env}{\int_0^1  [e^{i H s t} \int U_G D U_G^\dagger ~ dD ~ dU_G e^{-i H s t}, \rho(t)] ds} \\
    &= i t \partrace{env}{\int_0^1  [e^{i H s t} \int U_G \parens{\int D dD} U_G^\dagger ~ dU_G e^{-i H s t}, \rho(t)] ds},
\end{align}
but because $\int D ~dD$ is simply the mean of the eigenvalues this is 0 which implies $\frac{\partial}{\partial \alpha} \Phi(\rho) \big|_{\alpha = 0} = 0$. 

Now we can compute the second order term by differentiating Eq. \eqref{eq:first_order_alpha_derivative} before setting $\alpha \to 0$. Note that there are 3 locations for the derivative to act in each term, yielding 6 final terms. To give a sense of how each term is computed we will compute the first one explicitly and simply state the remaining terms.

\begin{align}
    \frac{\partial^2}{\partial \alpha^2} \Phi_G(\rho) \bigg|_{\alpha = 0} =& \frac{\partial}{\partial \alpha} \parens{\int_{0}^{1} e^{i s (H+\alpha G)t} (i t G) e^{i (1-s) (H+\alpha G)t} ds \rho e^{-i(H+\alpha G)t}} \bigg|_{\alpha=0} \nonumber \\
    &\text{ } +\frac{\partial}{\partial \alpha} \parens{ e^{i(H+\alpha G)t} \rho \int_{0}^1 e^{-i s (H+\alpha G) t} (- i t G) e^{-i (1-s) (H+\alpha G)t} ds } \bigg|_{\alpha = 0}
\end{align}
There are clearly six factors containing functions of $\alpha$ which leads to six terms after utilizing Duhamel's rule. We work through the first term in detail and will simply state the remaining terms in order from left to right and top to bottom. The first time can be simplified as
\begin{align}
    &i t\int_0^1 \parens{\frac{\partial}{\partial \alpha} e^{i s_1 (H+ \alpha G)t}} G e^{i(1-s_1)(H+\alpha G)t} ds_1 \rho e^{-i (H+\alpha G)t} \bigg|_{\alpha=0} \\
    &= (it)^2 \int_0^1 \int_0^1 e^{i s_1 s_2 (H+\alpha G)t} s_1 G e^{i s_1 (1-s_2) (H+\alpha G)t} ds_2 G e^{i(1-s_1) (H+\alpha G)t} ds_1 \rho e^{-i(H+\alpha G) t} \bigg|_{\alpha=0} \\
    &= -t^2 \int_0^1 \int_0^1 e^{i s_1 s_2 H t} G e^{-i s_1 s_2 H t} e^{i s_1 H t} G e^{-i s_1 H t} s_1 ds_1 ds_2 e^{i H t} \rho e^{-i H t} \\
    &= -t^2 \int_0^1 \int_0^1 G(s_1 s_2 t) G(s_1 t) s_1 ds_1 ds_2 \rho(t). 
\end{align}
The remaining terms we compute using a similar process, and are stated as
\begin{align}
    & -t^2 \int_0^1 \int_0^1 G(s_1 t) G((s_1 + s_2 - s_1 s_2) t) (1-s_1) ds_1 ds_2 \rho (t) \\
    & +t^2 \int_0^1 G(st) ds \rho(t) \int_0^1 G(st) ds \\
    & +t^2 \int_0^1 G(st) ds \rho(t) \int_0^1 G(st) ds \\
    & -t^2 \rho(t) \int_0^1 \int_0^1 G((1-s_1)t) G((1-s_1 s_2) t) s_1 ds_1 ds_2 \\
    & -t^2 \rho(t) \int_0^1 \int_0^1 G((1-s_1)t) G((1-s_1)(1 - s_2) t) (1-s_1) ds_1 ds_2.
\end{align}
For the last two terms we can make them look similar to the first two by redefining the integration variables. This leads to the simplified expression
\begin{align}
    \frac{\partial^2}{\partial \alpha^2} \Phi_G \bigg|_{\alpha = 0} &= 2 t^2 \int_0^1 G(st) ds \rho(t) \int_0^1 G(st) ds \label{eq:second_order_duhamel_one} \\
    &~ - t^2 \int_0^1 \int_0^1 \brackets{\rho(t) , G(s_1 t) G(s_1 s_2 t)}_+ s_1 ds_1 ds_2 \label{eq:second_order_duhamel_two}  \\
    &~ - t^2 \int_0^1 \int_0^1 \brackets{ \rho(t), G(s_1 t) G((s_1 + s_2 - s_1 s_2) t) }_+ (1-s_1) ds_1 ds_2, \label{eq:second_order_duhamel_three} 
\end{align}
where $[A,B]_+ := AB + BA$. 

Our next goal is to use this to compute the second order expansion for the expected channel, i.e by integrating over the randomized interaction $G$. We do so by computing the matrix elements $\bra{i,j} \int \frac{\partial^2}{\partial \alpha^2} \Phi_G(\rho) \big|_{\alpha = 0} dG \ket{k,l}$. This then puts us only a partial trace away from computing the second order term in the coupling coefficient expansion for the overall channel $\Phi$. Our main approach for computing these matrix elements is to factor a term, for example Eq. \eqref{eq:second_order_duhamel_one}, into three parts: a phase integral, a $G$ eigenvalue integral, and a Haar integral. To do so we make two assumptions: we assume that the input state is diagonal in the combined system-environment $H$ basis $\rho = \sum_{m,n} \rho_{m,n} \ketbra{m,n}{m,n}$, and second that the eigenvalues of the random interaction $G$ are i.i.d, which leads to a covariance matrix $Cov(\lambda_{i,j}, \lambda_{k,l}) = \sigma^2 \delta(i,j | k,l)$, where $\delta(i,j | k,l) := \delta_{i,k} \delta_{j,l}$ is a shorthand kronecker delta function. Note due to the invariance of the Haar eigenvectors we can always write the eigenvalues $D$ as diagonal in the 
\begin{align}
    2t^2 \int_0^1 G(s_1t) ds_1 \rho(t) \int_0^1 G(s_2 t) ds_2 &= 2 t^2 \bra{i,j} \int_{0}^1 \int_0^1 e^{i H s_1 t} G e^{-iH s_1 t} e^{i H t} \rho e^{-i H t} e^{i H s_2 t} G e^{-iH s_2 t} ds_1 ds_2 \ket{k,l} \\
    &= 2 t^2 \sum_{m,n} \rho_{m,n} \int_0^1 \int_0^1 e^{i(E_{i,j} - E_{m,n})s_1 t} e^{i(E_{m,n} - E_{k,l}) s_2 t} ds_1 ds_2 \bra{i,j}G \ketbra{m,n}{m,n} G \ket{k,l} \\
    &= \sum_{i',j',k',l',m,n} 2t^2 \rho_{m,n} \int_0^1 \int_0^1 e^{i(E_{i,j} - E_{m,n})s_1 t} e^{i(E_{m,n} - E_{k,l}) s_2 t} ds_1 ds_2 \nonumber \\
     &\quad \quad \quad \quad \times \lambda_{i',j'} \lambda_{k',l'} \bra{i,j} U_G \ket{i',j'} \bra{i',j'} U_G^\dagger \ket{m,n} \bra{m,n} U_G \ket{k',l'} \bra{k',l'} U_G^\dagger \ket{k,l}.
\end{align}
The phase, eigenvalue, and Haar contributions to this term are apparent. We can compute the remaining two terms Eqs. \eqref{eq:second_order_duhamel_two} and \eqref{eq:second_order_duhamel_three} as follows, starting with Eq. \eqref{eq:second_order_duhamel_two}
\begin{align}
    -t^2 \bra{i,j} \int_0^1 \int_0^1 [\rho(t), G(s_1 t) G(s_1 s_2 t)]_+ ~s_1 ds_1 ds_2 \ket{k,l} &= -t^2 (\rho_{i,j} + \rho_{k,l}) \sum_{i',j',k',l',m,n} \int_0^1 \int_0^1 e^{i(E_{i,j} - E_{m,n})s_1 t} e^{i(E_{m,n} - E_{k,l})s_1 s_2 t} s_1 ds_1 ds_2 \\
    &\times \lambda_{i',j'} \lambda_{k',l'} \bra{i,j} U_G \ket{i',j'} \bra{i',j'} U_G^\dagger \ket{m,n} \bra{m,n} U_G \ket{k',l'} \bra{k',l'} U_G^\dagger \ket{k,l},
\end{align}
followed by Eq. \eqref{eq:second_order_duhamel_three}
\begin{align}
    &-t^2 \bra{i,j} \int_0^1 \int_0^1 [\rho(t), G(s_1 t) G((s_1 + s_2 - s_1 s_2) t)]_+ ~ (1- s_1) ds_1 ds_2 \ket{k,l} \\
    &= -t^2 (\rho_{i,j} + \rho_{k,l}) \sum_{i',j',k',l',m,n} \int_0^1 \int_0^1 e^{i(E_{i,j} - E_{m,n})s_1 t} e^{i(E_{m,n} - E_{k,l})(s_1 + s_2 - s_1 s_2)t} (1-s_1)ds_1 ds_2 \\
    &\times \lambda_{i',j'} \lambda_{k',l'} \bra{i,j} U_G \ket{i',j'} \bra{i',j'} U_G^\dagger \ket{m,n} \bra{m,n} U_G \ket{k',l'} \bra{k',l'} U_G^\dagger \ket{k,l},
\end{align}
where the eigenvalue and Haar contributions are the same as the previous two terms. This allows us to simplify the total equation as
\begin{align}
    \bra{i,j} \frac{\partial^2}{\partial \alpha^2} \Phi_G(\rho) \bigg|_{\alpha = 0} \ket{k,l} &= t^2 \sum_{i',j',k',l',m,n} \int_0^1 \int_0^1 \bigg(  2 \rho_{m,n} e^{i(E_{i,j} - E_{m,n})s_1t} e^{i(E_{m,n} - E_{k,l})s_2 t}  \\
    &- (\rho_{i,j} + \rho_{k,l}) e^{i(E_{i,j} - E_{m,n})s_1 t} e^{i(E_{m,n} - E_{k,l})s_1 s_2 t} s_1 \\
    &- (\rho_{i,j} + \rho_{k,l}) e^{i(E_{i,j} - E_{m,n})s_1 t} e^{i(E_{m,n} - E_{k,l})(s_1 + s_2 - s_1 s_2)t} (1-s_1) \bigg) ds_1 ds_2 \\
    &\times \lambda_{i',j'} \lambda_{k',l'} \bra{i,j} U_G \ket{i',j'} \bra{i',j'} U_G^\dagger \ket{m,n} \bra{m,n} U_G \ket{k',l'} \bra{k',l'} U_G^\dagger \ket{k,l} \\
    &=: t^2 \sum_{i',j',k',l',m,n} C_{E} ~ C_{\lambda} ~ C_{H},
\end{align}
where $C_E$ captures the phase integrals, $C_{\lambda}$ the random eigenvalue factors, and $C_{H}$ the Haar contributions. 

We now average these over the randomized interaction measure $dG$. We first perform the eigenvalue integral as this will simplify the Haar integral significantly. 
\begin{align}
    \int \bra{i,j} \frac{\partial^2}{\partial \alpha^2} \Phi_G(\rho) \bigg|_{\alpha = 0} \ket{k,l} dG &= t^2 \sum_{i',j',k',l',m,n} C_E \int C_{\lambda} dD \int C_{H} dU_G.
\end{align}
We know that $\int C_{\lambda} dD = \sigma^2 \delta(i',j' | k',l')$ by construction. Due to the delta function we can simply set $(i',j') = (k',l')$ by performing the sum over $k',l'$, which turns the Haar integration into
\begin{align}
    \int C_{H} dU_G &= \int \bra{i,j} U_G \ket{i',j'} \bra{i',j'} U_G^\dagger \ket{m,n} \bra{m,n} U_G \ket{i',j'} \bra{i',j'} U_G^\dagger \ket{k,l} dU_G \\
    &= \int \bra{i,j} U_G \ket{i',j'}  \bra{m,n} U_G \ket{i',j'} \overline{\bra{m,n} U_G \ket{i',j'}} ~ \overline{ \bra{k,l} U_G \ket{i',j'} }~ dU_G \\
    &= \frac{\delta(i,j | k,l)}{\dim^2 - 1} \parens{\delta(i,j | m,n) + \frac{\dim - 1 - \delta(i,j | m,n)}{\dim}} \\
    &= \frac{\delta(i,j | k,l)}{\dim^2 - 1} \frac{\dim - 1}{\dim} \parens{1 + \delta(i,j | m,n)} \\
    &= \frac{\delta(i, j | k,l)}{\dim (\dim + 1)} (1 + \delta(i,j | m,n))
\end{align}
where we used Lemma \ref{lem:haar_two_moment} for the last line. This, combined with the eigenvalue integration, yields
\begin{align}
    \int \bra{i,j} \frac{\partial^2}{\partial \alpha^2} \Phi_G(\rho) \bigg|_{\alpha = 0} \ket{k,l} dG &= t^2 \sigma^2 \sum_{i',j',m,n} C_E(\rho; m,n; i,j) \frac{\delta(i, j | k,l)}{\dim (\dim + 1)} (1 + \delta(i,j | m,n)) \\
    &= t^2 \sigma^2 \sum_{m,n} C_E(\rho; m,n; i,j) \frac{\delta(i, j | k,l)}{\dim + 1
    } (1 + \delta(i,j | m,n))
\end{align}

Our next goal is to simplify the phase contributions to this second order correction. We use the fact that the Haar integration forces the index equalities $i = k, j = l$ to simplify the phase integrals. Substituting $E_{k,l} \mapsto E_{i,j}$ yields:
\begin{align}
    C_E &= 2 \rho_{m,n} \int_0^1 \int_0^1 e^{i(E_{i,j} - E_{m,n})(s_1 - s_2)t} ds_1 ds_2 \nonumber \\
    &~ ~ - 2 \rho_{i,j} \parens{\int_0^1 \int_0^1 e^{i (E_{i,j} - E_{m,n})s_1 (1- s_2)t}s_1 ds_1 ds_2 + \int_0^1 \int_0^1 e^{-i(E_{i,j} - E_{m,n})s_2(1-s_1)t}((1-s_1)ds_1 ds_2)} \label{eq:phase_int_equal_energy} \\
    &= \frac{4 \rho_{m,n}}{(E_{i,j} - E_{m,n})^2 t^2} (1 - \cos((E_{i,j} - E_{m,n})t)) - \frac{2 \rho_{i,j}}{(E_{i,j} - E_{m,n})^2 t^2} \parens{1 - e^{i (E_{i,j} - E_{m,n})t} + i (E_{i,j} - E_{m,n})t } \\
    & ~ ~ - \frac{2 \rho_{i,j}}{(E_{i,j} - E_{m,n})^2 t^2} \parens{1 - i (E_{i,j} - E_{m,n})t - e^{i(E_{i,j} - E_{m,n})t}} \\
    &= \frac{2}{(E_{i,j} - E_{m,n})^2 t^2} \parens{(2 \rho_{m,n} - \rho_{i,j}) - 2(\rho_{m,n} - \rho_{i,j}) \cos ((E_{i,j} - E_{m,n})t)}  
\end{align}

Note that this expression is indeterminate whenever $m = i, n = j$. To get around this we revisit Eq. \eqref{eq:phase_int_equal_energy} and isolate the condition $E_{m,n} = E_{i,j}$. In this scenario we have
\begin{align}
    C_E(m,n;i,j | E_{m,n} = E_{i,j}) &= 2 \rho_{m,n} \int_0^1 \int_0^1 1 ds_1 ds_2 - 2 \rho_{i,j} \parens{\int_0^1 \int_0^1 s_1 ds_1 ds_2 + \int_0^1 \int_0^1 (1-s_1) ds_1 ds_2} \\
    &= 2 (\rho_{m,n} - \rho_{i,j}).
\end{align}
Now it is apparent that if $(m,n) = (i,j)$ this term clearly is zero. It is not obvious that in other situations this is zero. Expanding the $\rho_{m,n}$ term, we see that if $\beta_{env} = \beta_{sys}$
\begin{align}
    \rho_{m,n} &= \frac{e^{-\beta_{sys} E_m}}{\partfun_{sys}} \frac{e^{-\beta_{env} E_{n}}}{\partfun_{env}} \\
    \xRightarrow{\beta_{env} = \beta_{sys}} \rho_{m,n} &= \frac{e^{-\beta_{sys}E_{m,n}}}{\partfun_{sys} \partfun_{env}} \\
    \xRightarrow{E_{m,n} = E_{i,j}} \rho_{m,n} &= \rho_{i,j}.
\end{align}
This tells us that when the system has thermalized ($\rho = \partfun_{sys}^{-1} e^{-\beta H_{sys}} \otimes \partfun_{env}^{-1} e^{-\beta H_{env}}$), equal energy contributions ($E_{m,n} = E_{i,j}$) are zero. However at non-equilibrium states where $\beta_{env} \neq \beta_{sys}$ we cannot neglect these non-zero contributions. 

For this simply note that each of the phases in the exponents of the integrals are 0, leading to $C_E = 0$. This means we can restrict ourselves to $m \neq i, n \neq j$. 

\begin{align}
    \int \bra{i,j} \frac{\partial^2}{\partial \alpha^2} \Phi_G(\rho) \bigg|_{\alpha = 0} \ket{i,j} dG &= \frac{2 \sigma^2}{\dim + 1} \sum_{(m,n) : E_{m,n} \neq E_{i,j}} \frac{(2 \rho_{m,n} - \rho_{i,j}) - 2(\rho_{m,n} - \rho_{i,j}) \cos ((E_{i,j} - E_{m,n})t)}{(E_{i,j} - E_{m,n})^2} \nonumber \\
    &~ + \frac{2 \sigma^2}{\dim + 1} \sum_{(m,n) : E_{m,n} = E_{i,j}} 2 (\rho_{m,n} - \rho_{i,j}) \label{eq:second_order_final}
\end{align}

\subsection{Convergence to low temperature system state}
For simplicity later on we make the following definitions:
\begin{align}
    T(\rho) &:= \alpha^2 \int \partrace{Env}{ \frac{\partial^2}{\partial \alpha^2} \Phi_G (\rho) \bigg_{\alpha=0} } dG \\
    R(\rho) &:= \Phi(\rho) - \rho - T(\rho),
\end{align} 
aka the remainder term in the $\alpha$ expansion. It should be clear that $\norm{R} \in \bigo{\alpha^3}$ and $\norm{T} \in \bigo{\alpha^2}$.

\subsection{Linearization of $\beta$}
In order to show convergence to a thermal state we now will linearize the one norm of our channel with respect to the difference between the system's starting inverse temperature and the environment's inverse temperature, $\beta_{env} - \beta_{sys} := \gamma$. Our goal is to show $\norm{\Phi(\rho(\gamma)) - \rho(0)}_1 \leq \norm{\rho(\gamma) - \rho(0)}_1$, where $\rho(\gamma) = e^{- \beta_{sys} H_sys} \partfun_{sys}(\gamma)^{-1} = e^{-(\beta_{env} - \gamma) H_{sys}} \partfun_{sys}(\gamma)^{-1}$, where $\partfun_{sys}(\gamma) = \trace{e^{-(\beta_{env} - \gamma) H_{sys}}}$.

We start by computing $\frac{\partial}{\partial \gamma}\rho(\gamma)$, which will be used in linearizations of the channel:
\begin{align}
    \frac{\partial}{\partial \gamma} \rho(\gamma) &= \frac{\partial}{\partial \gamma} \parens{e^{-\beta_{env} H_{sys} + \gamma H_{sys}} \partfun_{sys}(\gamma)^{-1}} \\
    &= H_{sys} \frac{e^{-\beta_{env} H_{sy} + \gamma H_{sys}}}{\partfun_{sys}(\gamma)} - \frac{e^{-\beta_{env} H_{sys} + \gamma H_{sys}}}{\partfun_{sys}(\gamma)^2} \frac{\partial \partfun_{sys}(\gamma)}{\partial \gamma} \\
    &= \frac{e^{-\beta_{env} H_{sy} + \gamma H_{sys}}}{\partfun_{sys}(\gamma)} \parens{H_{sys} - \frac{\trace{H_{sys} e^{-\beta_{env} H_{sys} + \gamma H_{sys}}} }{\partfun_{sys}(\gamma)}} \\
    &= \rho(\gamma) \parens{H_{sys} - \trace{H_{sys} \rho(\gamma)}}.
\end{align}
This allows us to compute the linearization of the channel:
\begin{align}
    \Phi(\rho(\gamma)) = \Phi(\rho(0)) + \gamma \frac{\partial}{\partial \gamma} \Phi(\rho(\gamma))\bigg|_{\gamma = 0} + \bigo{\gamma^2}
\end{align}

Carrying the linearization to the second order term results in a lot of factors of the form $\frac{e^{-\beta_E E_{m,n}}}{\partfun(0)} (\bra{m} H_{sys} \ket{m} - \trace{\rho(0) H_{sys}})$. We need to know when these are negative, so here we go:
\begin{align}
    \frac{e^{-\beta_E E_{m,n}}}{\partfun(0)} \parens{\bra{m} H_{sys} \ket{m} - \trace{\rho(0) H_{sys}}} & \leq 0 \\
    \implies \bra{m} H_{sys} \ket{m} \leq \trace{\rho(0) H_{sys}}
\end{align}
What I want to know is what is: (I don't think the partition function should be a function of x, think of this as just selecting the energy to evaluate the above. By selecting a different energy I'm not changing the partition function, but I'm changing this specific matrix element)
\begin{align}
    \frac{\partial}{\partial x} \frac{e^{-\beta_E (x + c)}}{\partfun}(x - E) &= (-\beta_E) \frac{e^{-\beta_E (x + c)}}{\partfun}(x - E) + \frac{e^{-\beta_E (x + c)}}{\partfun} \\
    &= \frac{e^{-\beta_E (x + c)}}{\partfun} \parens{1 + \beta_E (E - x)}
\end{align}



\subsection{Harmonic Oscillator Fixed Point}
Now consider the situation of a system and environment which are both harmonic oscillators of frequency $\omega$, $H_{sys} = \hbar \omega \sum_{i=0}^{N_{sys}} (0.5 + i) \ketbra{i}{i}$ and $H_{env} = \hbar \omega \sum_{i=0}^{N_{env}} (0.5 + i) \ketbra{i}{i}$, yeilding $H = \sum_{i,j} \hbar \omega (1 + i + j) \ketbra{i,j}{i,j}$. We set $\hbar = \omega = 1$ to avoid dimensionful quantities. 

Our hunch is that the second order correction of $\Phi(\rho)$ vanishes whenever $\rho$ is a thermal state of the joint system-environment hamiltonian, i.e. $\rho = \sum_{i,j} \ketbra{i}{i} \otimes \ketbra{j}{j}\rho_{i,j} = \frac{e^{-\beta (1 + i + j)}}{\sum_{e^{-\beta(1+  i + j)}}} \ketbra{i}{i} \otimes \ketbra{j}{j}$. Before we compute this second-order correction, note that the assumption of a thermal state input eliminates the sum over equal energy contributions in Eq. \eqref{eq:second_order_final}. Further, in the interest of simplifying the expression as much as possible, we will only consider the time-averaged contributions $\frac{1}{T} \int_0^T \Phi(\rho, t) dt$, this pretty much just eliminates the cosine term in Eq. \eqref{eq:second_order_final}.

First define $\rho(\gamma) := \frac{e^{-(\beta_E -\gamma) H_{sys}}}{\partfun_{sys}(\gamma)}$
Our main goal is to show $\norm{\Phi(\rho(\gamma)) - \rho(0)} \leq \norm{\rho(\gamma) - \rho(0)}$, in other words that a higher temperature state ($\beta_{sys} = \beta_{env} - \gamma$) gets closer to a lower temperature state after application of $\Phi$. In order to do this we first use our power series of $\Phi$ in terms of the coupling constant $\alpha$ and use the Schatten-1 norm:
\begin{align}
    \norm{\Phi(\rho(\gamma)) - \rho(0)}_1 &= \norm{\rho(\gamma) + T(\rho(\gamma)) + R(\rho(\gamma)) - \rho(0)}_1 \\
    &= \norm{ \sum_{i} \parens{ e^{-(\beta_{env} + \gamma) E_i} \partfun_{S}^{-1}(\gamma) + T_{i,i}(\rho(\gamma)) - e^{-\beta_{env} E_i} \partfun_{S}^{-1}(\gamma) }\ketbra{i}{i}} + \bigo{\alpha^{4}} \\
    &= \sum_i \abs{ e^{-(\beta_{env} + \gamma) E_i} \partfun_{S}^{-1}(\gamma) + T_{i,i}(\rho(\gamma)) - e^{-\beta_{env} E_i} \partfun_{S}^{-1}(\gamma) } + \bigo{\alpha^4},
\end{align}
where we can avoid using the triangle inequality as our operator is already diagonalized. \todo{Does the $\bigo{\alpha^4}$ term not pick up dimensional factors from the schatten-1 norm?} Now we have to use a linearization of the operator $\rho(\gamma)$ as well as the second order corrections $T_{i,i}$.
\begin{align}
    \rho(\gamma) = \frac{e^{-\beta_{env} H_{sys}}}{\partfun_{sys}(\gamma=0)} + \gamma \frac{\partial}{\partial \gamma} \frac{e^{-\beta_{env} H_{sys} + \gamma H_{sys}}}{\partfun_{sys}(\gamma)} \bigg|_{\gamma=0} + \bigo{\gamma^2}.
\end{align}
The derivative is easy to compute (I think I wrote this down on the overleaf) 
\begin{equation}
    \frac{\partial}{\partial \gamma} \frac{e^{-\beta_{env} H_{sys} + \gamma H_{sys}}}{\partfun_{sys}(\gamma)} = e^{-\beta_{env}}
\end{equation}



% Now we compute the second term, Eq. \eqref{eq:second_order_duhamel_two}. We avoid duplicating similar steps to the computation of the first computation and simply state the results (aka I need to write this up in an appendix.)
% The second term, after writing everything in terms of sums over matrix elements, becomes
% \begin{align}
%     -t^2 \parens{\bra{i,j} \rho \ket{i,j} + \bra{k,l} \rho \ket{k,l}} \sum_{i',j',k',l',m,n} \int_0^1 \int_0^1 e^{i(E_{i,j} - E_{m,n})s_1 t} e^{i(E_{m,n} - E_{k,l})s_1 s_2 t} s_1 ds_1 ds_2 \\
%     \times \bra{i',j'} D \ket{i',j'} \bra{k',l'} D \ket{k',l'} \\
%     \times \bra{i,j} U_G \ket{i',j'} \bra{m,n} U_G \ket{k',l'} \bra{m,n} \overline{U_G} \ket{i',j'} \bra{k,l} \overline{U_G} \ket{k',l'}
% \end{align}
% Plugging in similar results and integrating over the randomized interaction yields 
% \begin{align}
%     \sum_{i',j',k',l',m,n}\frac{\bra{i,j} \rho \ket{i,j} \sigma^2 }{E_{m,n} - E_{k,l}} \delta_{i',k'} \delta_{j',l'} \delta_{i,k} \delta_{j,l} 
% \end{align}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Energy and Entropic concerns}
One requirement that our construction should satisfy is that a system in a thermal state should be invariant under contact with an environment at the same temperature. Formally, we would like that $\Phi \parens{\frac{e^{-\beta H_{sys}}}{\partfun_{sys}} \otimes \frac{e^{- \beta H_{env}}}{\partfun_{env}}} = \frac{e^{-\beta H_{sys}}}{\partfun_{sys}}$. Exact equality may be too strong to enforce, so we instead consider that the energy of the system remains unchanged after coupling with the environment. 

\begin{equation}
    \trace{H_{sys} \frac{e^{-\beta H_{sys}}}{\partfun_{sys}}} = \trace{H_{sys} \Phi \parens{\frac{e^{-\beta H_{sys}}}{\partfun_{sys}} \otimes \frac{e^{- \beta H_{env}}}{\partfun_{env}}}}.
\end{equation}
Now we look at the RHS in detail
\begin{align}
    \trace{H_{sys} \Phi \parens{\rho} } &= \trace{ H_{sys} \partrace{env}{\int e^{i \widetilde{H} t} \rho e^{-i \widetilde{H} t} dG}} \\
    &= \int \trace{H_{sys} \otimes \openone_{env} e^{i \widetilde{H} t} \rho e^{-i \widetilde{H} t} } dG \\
    &=  \trace{\int e^{- i (H + \alpha G) t} H_{sys} \otimes \openone_{env} e^{+ i (H + \alpha G) t} dG ~ \rho } 
\end{align}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Numerics}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Approximating $e^{i (H + \alpha G) t}$ evolution}


\section{Leftovers}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Simplifying $\Phi(\rho)$ with Perturbation Theory}
The goal is to use perturbation theory to write the output of the channel in terms of powers of the coupling strength $\alpha$. It remains to be seen if first order perturbation theory will be enough. We also are specifically interested when $\rho$ is a product state of thermal states, in other words $\rho_{PS} = \frac{e^{-\beta_1 H_1}}{\partfun_1} \otimes \frac{e^{-\beta_2 H_2}}{\partfun_2}$. We also denote the action of our channel with respect to a particular choice of $G$ as $\Phi_G$, which combined with linearity of partial traces gives $\Phi = \int dG \Phi_G$. 
\begin{align}
    \Phi_G(\rho_{PS}) &= \partrace{2}{e^{+i \widetilde{H} t} \rho_{PS} e^{-i \widetilde{H} t}} \\
    &= \sum_{k} \openone \otimes v_k^* \parens{\sum_{i, j} e^{i \widetilde{\eta}_{i, j} t} \widetilde{\Pi}_{i,j}} \rho_{PS} \parens{ \sum_{m, n} e^{i \widetilde{\eta}_{m, n} t} \widetilde{\Pi}_{m,n} }
\end{align}
Our next goal is to analyze $e^{i \widetilde{\eta}_{i,j} t} \widetilde{\Pi}_{i,j}$ using time-independent perturbation theory. Our goal is to write $e^{i \widetilde{\eta}_{i,j} t}$ as a power series in terms of $\alpha$, which is given by perturbation theory for $\widetilde{H} = H + \alpha G$. We first write the perturbation series for $\widetilde{\eta}$ as 
\begin{equation}
    \widetilde{\eta}_{i,j} = \eta_{i,j} + \alpha (u_i \otimes v_j)^* G (u_i \otimes v_j) + \alpha^2 \sum_{(i',j') \neq (i,j)}  \frac{\abs{(u_i \otimes v_j)^* G (u_{i'} \otimes v_{j'})}^{2}}{\eta_{i,j} - \eta_{i',j'}} + \bigo{\alpha^3}.
\end{equation}
To simplify the notation, we introduce the indexing $G(i,j,k,l) := (u_i \otimes v_j)^* G (u_k \otimes v_l)$. $G(i,j)$ without a second pair of indices denotes the diagonal matrix element $(u_i \otimes v_j)^* G (u_i \otimes v_j)$. The Taylor's Series for $e^{i \widetilde{\eta}_{i,j} t}$ is
\begin{align}
    e^{i \widetilde{\eta}_{i,j} t} &= e^{i \eta_{i,j} t} \\
    &\quad + \frac{\partial \widetilde{\eta}_{i,j}}{\partial \alpha} e^{i \widetilde{\eta}_{i,j}t} \bigg|_{\alpha = 0} i \alpha t \\
    &\quad + \frac{ i\alpha^2 t}{2!} \frac{\partial^2 \widetilde{\eta}_{i,j}}{\partial \alpha^2} e^{i \widetilde{\eta}_{i,j}t}\bigg|_{\alpha=0} \\
    &\quad - \frac{\alpha^2 t^2}{2!} \parens{\frac{\partial \widetilde{\eta}_{i,j}}{\partial \alpha}}^2 e^{i \widetilde{\eta}_{i,j} t} \bigg|_{\alpha=0} + \bigo{\alpha^3} .
\end{align}
These are rather straightforward to compute and plug in, yielding
\begin{equation}
    e^{i \widetilde{\eta}_{ij} t} = e^{i \eta_{ij} t}\parens{1 + i \alpha t G(i,j) - \frac{\alpha^2 t^2}{2} G(i,j)^2 + i \frac{\alpha^2 t}{2} \sum_{(i',j') \neq (i,j)}\frac{\abs{G(i',j',i,j)}^2}{\eta_{ij} - \eta_{i' j'}} + \bigo{\alpha^3}}.
\end{equation}
This is sloppy, need to be able to bound the $\bigo{\alpha^3}$ terms better. Also note that $G(i,j)$ is a real Gaussian variable, the realness is due to the Hermiticity constraint on $G$. 

The other quantity we need to compute a perturbation series for is $\widetilde{\Pi}_{ij}$. We first need to compute the perturbation series for the eigenvectors of $H$, which we do to second order
\begin{align}
    \widetilde{u_i \otimes v_j} &= u_i \otimes v_j \\
    &\quad + \alpha \sum_{(i',j') \neq (i,j)} u_{i'} \otimes v_{j'} \parens{  \frac{G(i,j,i',j')}{\eta_{i,j} - \eta_{i',j'}} } \\
    &\quad + \alpha^2 \sum_{(i',j') \neq (i,j)} u_{i'} \otimes v_{j'} \parens{ \sum_{(i'',j'') \neq (i,j)} \frac{G(i,j,i'',j'') G(i'',j'',i',j')}{(\eta_{i,j} - \eta_{i'',j''})(\eta_{i,j} - \eta_{i'',j''})} -  \frac{G(i,j,i,j) G(i,j,i',j')}{(\eta_{i,j} - \eta_{i',j'})^2}} \\
    &\quad + \bigo{\alpha^3}.
\end{align}
Now we need to compute the perturbed eigenspace projectors
\begin{align}
    \widetilde{\Pi}_{i,j} &= \Pi_{i,j} \\
    & \quad + \alpha \sum_{(i',j') \neq (i,j)} u_{i'} u_i^* \otimes v_{j'} v_j^* \parens{  \frac{G(i,j,i',j')}{\eta_{i,j} - \eta_{i',j'}} } + \sum_{(i',j') \neq (i,j)} u_i u_{i'}^* \otimes v_j v_{j'}^* \parens{  \frac{G(i,j,i',j')^*}{\eta_{i,j} - \eta_{i',j'}} } \\
    & \quad + \alpha^2 \sum_{(i',j') \neq (i,j)} u_{i'} u_i^* \otimes v_{j'} v_j^* \parens{ \sum_{(i'',j'') \neq (i,j)} \frac{G(i,j,i'',j'') G(i'',j'',i',j')}{(\eta_{i,j} - \eta_{i'',j''})(\eta_{i,j} - \eta_{i'',j''})} -  \frac{G(i,j,i,j) G(i,j,i',j')}{(\eta_{i,j} - \eta_{i',j'})^2}} \\
    & \quad + \alpha^2 \sum_{(i',j') \neq (i,j)} u_i u_{i'}^* \otimes v_j v_{j'}^* \parens{ \sum_{(i'',j'') \neq (i,j)} \frac{G(i,j,i'',j'')^* G(i'',j'',i',j')^*}{(\eta_{i,j} - \eta_{i'',j''})(\eta_{i,j} - \eta_{i'',j''})} -  \frac{G(i,j,i,j)^* G(i,j,i',j')^*}{(\eta_{i,j} - \eta_{i',j'})^2}} \\
    & \quad + \alpha^2 \sum_{(i',j') \neq (i,j)} \sum_{(i'',j'') \neq (i,j)} u_{i'}u_{i''}^* \otimes v_{j'} v_{j''}^* \frac{G(i,j,i',j') G(i,j,i'',j'')^*}{(\eta_{i,j} - \eta_{i',j'})(\eta_{i,j} - \eta_{i'',j''})} \\
    & \quad + \bigo{\alpha^3}.
\end{align}

This allows us to write the output of the channel $\Phi$ as a power series in $\alpha$. The expressions can become quite cumbersome, so we introduce the following notation:
\begin{align}
    M_{i,j,i',j'} &:=  u_{i'} u_i^* \otimes v_{j'} v_j^* \parens{  \frac{G(i,j,i',j')}{\eta_{i,j} - \eta_{i',j'}} } +  u_i u_{i'}^* \otimes v_j v_{j'}^* \parens{  \frac{G(i,j,i',j')^*}{\eta_{i,j} - \eta_{i',j'}} } \\
    N_{i,j,i',j'} &:= u_{i'} u_i^* \otimes v_{j'} v_j^* \parens{ \sum_{(i'',j'') \neq (i,j)} \frac{G(i,j,i'',j'') G(i'',j'',i',j')}{(\eta_{i,j} - \eta_{i'',j''})(\eta_{i,j} - \eta_{i'',j''})} -  \frac{G(i,j,i,j) G(i,j,i',j')}{(\eta_{i,j} - \eta_{i',j'})^2}} \\
    & \quad + \sum_{(i'',j'') \neq (i,j)} u_{i'}u_{i''}^* \otimes v_{j'} v_{j''}^* \frac{G(i,j,i',j') G(i,j,i'',j'')^*}{(\eta_{i,j} - \eta_{i',j'})(\eta_{i,j} - \eta_{i'',j''})}
\end{align}
which captures the first and second order corrections to the eigenspace projectors. We can then simplify
\begin{align}
    \widetilde{\Pi}_{i,j} &= \Pi_{i,j} + \alpha \sum_{(i',j') \neq (i,j)} M_{i,j,i',j'} + \alpha^2 \sum_{(i',j') \neq (i,j)} N_{i,j,i',j'} + \bigo{\alpha^3}
\end{align}
The second order corrections have 10 possible sources for terms, however many are hermitian conjugates of priors, so if herm. conj. appears it refers to the hermitian conjugate of the entire previous line.
\newpage
\begin{equation}
    e^{+i(H + \alpha G)t} \rho e^{-i (H + \alpha G) t}
\end{equation}
\begin{align}
\alpha^0 :& e^{+i H t} \rho e^{-i H t} \\
 \alpha^1 :& \sum_{i,j} e^{i\eta_{i,j}t} \parens{i t G(i,j) \Pi_{i,j} + \sum_{(i',j') \neq (i,j)} M_{i,j,i',j'}} \rho e^{- i H t} \\
 &+ \text{herm. conj.} \\
 \alpha^2 :& \sum_{i,j} i t G(i,j) e^{i \eta_{i,j}} \Pi_{i,j} \rho \sum_{k,l} (-i t) G(k,l)^* e^{-i \eta_{k,l}t} \Pi_{k,l} \\
 &+ \sum_{i,j} e^{i \eta_{i,j} t} \sum_{(i',j') \neq (i,j)} M_{i,j,i',j'} \rho \sum_{k,l} (-i t) G(k,l) e^{-i \eta_{k,l} t} \Pi_{k,l} \\
 &+ \text{herm. conj.} \\
 &+ \sum_{i,j} e^{i \eta_{i,j} t} \sum_{(i',j') \neq (i,j)} M_{i,j,i',j'} \rho \sum_{k,l} e^{-i \eta_{k,l} t} \sum_{(k',l') \neq (k,l)} M_{k,l,k',l'}\\
 &+  \sum_{i,j} e^{i \eta_{i,j} t} \parens{- \frac{t^2 G(i,j)^2}{2} + i \frac{t}{2} \sum_{(i',j') \neq (i,j)} \frac{\abs{G(i,j,i',j')}^2}{\eta_{i,j} - \eta_{i',j'}} } \rho e^{- i H t} \\
 &+ \text{herm. conj.} \\
 &+ \sum_{i,j} e^{i \eta_{i,j} t} \sum_{(i',j') \neq (i,j)} N_{i,j,i',j'} \rho e^{-i H t} \\
 &+ \text{herm. conj.} \\
 &+ \sum_{i,j} i t G(i,j) e^{i \eta_{i,j} t} \sum_{(i',j') \neq (i,j)} M_{i,j,i',j'} \rho e^{-i H t} \\
 &+ \text{herm. conj.}.
\end{align}

Two potential issues. 1) How can we normalize the output state? This may depend on how we approach the second. 2) How do we bound the remaining terms in the perturbation series? Are there any dumb bounds I can work out? 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Simplifying $\Phi(\rho)$ with Trotter}
The idea here is to try and see what very short time evolution does to our channel. At the very least this might give some intuition as to what is happening?
\begin{align}
    \Phi_G(\rho_{PS}) &= \partrace{2}{e^{+i\widetilde{H}t} \rho_{PS} e^{-i \widetilde{H} t}} \\
    &= \partrace{2}{\parens{e^{i G \alpha t} e^{i H t} + \bigo{t^2}} \rho_{PS} \parens{e^{-iHt} e^{-i G \alpha t} + \bigo{t^2}}} \\
    &= \partrace{2}{e^{i G \alpha t} \rho_{PS} e^{-i G \alpha t}} + \bigo{t^2} 
\end{align}

\section{Energy and Entropic concerns}
One requirement that our construction should satisfy is that a system in a thermal state should be invariant under contact with an environment at the same temperature. Formally, we would like that $\Phi \parens{\frac{e^{-\beta H_{sys}}}{\partfun_{sys}} \otimes \frac{e^{- \beta H_{env}}}{\partfun_{env}}} = \frac{e^{-\beta H_{sys}}}{\partfun_{sys}}$. Exact equality may be too strong to enforce, so we instead consider that the energy of the system remains unchanged after coupling with the environment. 

\begin{equation}
    \trace{H_{sys} \frac{e^{-\beta H_{sys}}}{\partfun_{sys}}} = \trace{H_{sys} \Phi \parens{\frac{e^{-\beta H_{sys}}}{\partfun_{sys}} \otimes \frac{e^{- \beta H_{env}}}{\partfun_{env}}}}.
\end{equation}
Now we look at the RHS in detail
\begin{align}
    \trace{H_{sys} \Phi \parens{\rho} } &= \trace{ H_{sys} \partrace{env}{\int e^{i \widetilde{H} t} \rho e^{-i \widetilde{H} t} dG}} \\
    &= \int \trace{H_{sys} \otimes \openone_{env} e^{i \widetilde{H} t} \rho e^{-i \widetilde{H} t} } dG \\
    &=  \trace{\int e^{- i (H + \alpha G) t} H_{sys} \otimes \openone_{env} e^{+ i (H + \alpha G) t} dG ~ \rho }
\end{align}

 \subsection{Phase Contribution complicated}
 Now we investigate the phase integrals $C_E$. 
 \begin{align}
     C_E &= \int_0^1 \int_0^1 \bigg(  2 \rho_{m,n} e^{i(E_{i,j} - E_{m,n})s_1t} e^{i(E_{m,n} - E_{k,l})s_2 t}  \\
     &- (\rho_{i,j} + \rho_{k,l}) e^{i(E_{i,j} - E_{m,n})s_1 t} e^{i(E_{m,n} - E_{k,l})s_1 s_2 t} s_1 \\
     &- (\rho_{i,j} + \rho_{k,l}) e^{i(E_{i,j} - E_{m,n})s_1 t} e^{i(E_{m,n} - E_{k,l})(s_1 + s_2 - s_1 s_2)t} (1-s_1) \bigg) ds_1 ds_2 \\
 \end{align}
 These can be solved analytically as
 \begin{align}
     \int_0^1 \int_0^1 e^{i(E_{i,j} - E_{m,n})s_1t} e^{i(E_{m,n} - E_{k,l})s_2 t} ds_1 ds_2 &= \frac{(e^{i(E_{i,j} - E_{m,n})t} - 1)(e^{i(E_{m,n} - E_{k,l})t} - 1)}{t^2 (E_{i,j} - E_{m,n})(E_{k,l} - E_{m,n})} \\
     \int_0^1 \int_0^1 e^{i(E_{i,j} - E_{m,n})s_1 t} e^{i(E_{m,n} - E_{k,l})s_1 s_2 t} s_1 ds_1 ds_2 &= \nonumber \\
     \frac{e^{i(E_{i,j} - E_{k,l})t}(E_{i,j} - E_{m,n}) + (E_{m,n} - E_{k,l}) - e^{i(E_{i,j} - E_{m,n})t}(E_{i,j} - E_{k,l})}{t^2(E_{i,j} - E_{m,n})(E_{k,l} - E_{m,n})(E_{i,j} - E_{k,l})} \\
     \int_0^1 \int_0^1 e^{i(E_{i,j} - E_{m,n})s_1 t} e^{i(E_{m,n} - E_{k,l})(s_1 + s_2 - s_1 s_2)t} (1-s_1) ds_1 ds_2 &= \nonumber \\
     \frac{-(E_{i,j} - E_{m,n}) + e^{i(E_{m,n} - E_{k,l})t}\parens{E_{i,j} - E_{k,l} - e^{i(E_{i,j} - E_{m,n})t}(E_{m,n} - E_{k,l})}}{t^2 (E_{i,j} - E_{m,n})(E_{m,n} - E_{k,l})(E_{i,j} - E_{k,l})}
 \end{align}
 Now we introduce some minor notation to help readability $\Delta_{ij,kl} := E_{i,j} - E_{k,l}$. This reduces the phase contribution to
 \begin{align}
      t^2 C_E(\rho) = &e^{i\Delta_{ij,kl}t} \parens{\frac{2 \rho_{m,n}}{\Delta_{ij,mn} \Delta_{kl,mn}} + \frac{(\rho_{ij} + \rho_{k,l}) \Delta_{ij,mn}}{\Delta_{ij,kl} \Delta_{ij,mn} \Delta_{kl,mn}}} \\
     +& e^{i \Delta_{ij,mn}t} \parens{\frac{- 2 \rho_{m,n}}{\Delta_{ij,mn} \Delta_{kl,mn}} - \frac{(\rho_{ij} + \rho_{k,l}) \Delta_{mn,kl}}{\Delta_{ij,mn} \Delta_{ij,kl} \Delta_{kl,mn}} - \frac{(\rho_{i,j} + \rho_{k,l})\Delta_{ij,kl}}{\Delta_{ij,mn} \Delta_{ij,kl} \Delta_{kl,mn}}} \\
     +& e^{i \Delta_{mn,kl}t} \parens{\frac{- 2 \rho_{m,n}}{\Delta_{ij,mn} \Delta_{kl,mn}} - \frac{(\rho_{i,j} + \rho_{k,l}) \Delta_{ij,kl}}{\Delta_{ij,mn} \Delta_{ij,kl} \Delta_{kl,mn}}} \\
     +& \parens{2 \rho_{m,n} + (\rho_{i,j} + \rho_{k,l}) \frac{\Delta_{mn,kl} + \Delta_{ij,mn}}{\Delta_{ij,kl} \Delta_{ij,mn} \Delta_{kl,mn}}}
 \end{align}
 
 Since we have the factor of $\delta_{i,j | k,l}$ from the Haar integral contribution we can further simplify these as
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Approximating $e^{i (H + \alpha G) t}$ evolution}

\bibliographystyle{unsrt}
\bibliography{bib}

\end{document}
